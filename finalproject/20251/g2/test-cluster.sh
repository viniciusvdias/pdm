#!/bin/bash

# Script para testar o funcionamento do cluster Apache Spark
# Autor: Grupo 2

set -e

echo "ğŸ§ª Testando funcionamento do cluster Apache Spark no Docker Swarm"
echo "=================================================================="

# Verificar se estÃ¡ em ambiente Swarm
if ! docker info | grep -q "Swarm: active"; then
    echo "âŒ Docker Swarm nÃ£o estÃ¡ ativo!"
    echo "Execute: docker swarm init"
    exit 1
fi

echo "âœ… Docker Swarm estÃ¡ ativo"

# Verificar nÃ³s do cluster
echo ""
echo "ğŸ” Verificando nÃ³s do cluster:"
docker node ls

# Verificar se a imagem existe
if ! docker image inspect ru-ufla-analytics:latest > /dev/null 2>&1; then
    echo ""
    echo "âš ï¸  Imagem ru-ufla-analytics:latest nÃ£o encontrada. Construindo..."
    docker build -t ru-ufla-analytics:latest .
fi

echo ""
echo "âœ… Imagem ru-ufla-analytics:latest disponÃ­vel"

# Verificar se a stack jÃ¡ estÃ¡ rodando
if docker stack ls | grep -q "ru-analytics"; then
    echo ""
    echo "âš ï¸  Stack ru-analytics jÃ¡ estÃ¡ rodando. Removendo para teste limpo..."
    docker stack rm ru-analytics
    echo "â³ Aguardando remoÃ§Ã£o completa..."
    sleep 30
fi

# Fazer deploy da stack
echo ""
echo "ğŸš€ Fazendo deploy da stack no cluster..."
docker stack deploy -c docker-compose.swarm.yml ru-analytics

echo ""
echo "â³ Aguardando inicializaÃ§Ã£o dos serviÃ§os..."
sleep 45

# Verificar serviÃ§os
echo ""
echo "ğŸ“Š Status dos serviÃ§os:"
docker stack services ru-analytics

# Verificar se todos os serviÃ§os estÃ£o running
echo ""
echo "ğŸ” Verificando tasks dos serviÃ§os:"
docker stack ps ru-analytics --no-trunc

# Aguardar mais tempo para garantir que tudo esteja rodando
echo ""
echo "â³ Aguardando estabilizaÃ§Ã£o do cluster..."
sleep 60

# Testar conectividade Spark
echo ""
echo "ğŸ§ª Testando conectividade com Spark Master..."

# Criar um serviÃ§o temporÃ¡rio para testar
docker service create --name test-spark-connectivity \
    --network ru-analytics_spark-network \
    --env SPARK_MASTER_URL=spark://spark-master:7077 \
    --env DOCKER_SWARM_MODE=true \
    --constraint 'node.role == manager' \
    --restart-condition none \
    ru-ufla-analytics:latest \
    /app/.venv/bin/python -m src.main test-spark --master-url spark://spark-master:7077

echo ""
echo "â³ Aguardando teste de conectividade..."
sleep 30

# Verificar logs do teste
echo ""
echo "ğŸ“‹ Logs do teste de conectividade:"
docker service logs test-spark-connectivity

# Limpar serviÃ§o de teste
docker service rm test-spark-connectivity

# Mostrar resumo final
echo ""
echo "ğŸ“ˆ Resumo do Cluster:"
echo "==================="
echo "ğŸ”¥ Spark Master UI: http://localhost:8080"
echo "ğŸ“Š Spark App UI: http://localhost:4040 (durante execuÃ§Ã£o)"
echo "ğŸ‘· Workers UIs: http://localhost:8081-8084"
echo ""
echo "ğŸ“Š Recursos configurados:"
echo "- 8 Workers distribuÃ­dos nas 4 VMs"
echo "- 4 cores por worker (32 cores total)"
echo "- 12GB RAM por worker (96GB total)"
echo "- Driver: 2 cores, 8GB RAM"
echo ""
echo "ğŸš€ Comandos Ãºteis:"
echo "- Status: ./bin/run_project.sh swarm-status"
echo "- AnÃ¡lise: ./bin/run_project.sh swarm-analyze complete"
echo "- Logs: ./bin/run_project.sh swarm-logs"
echo "- Escalar: ./bin/run_project.sh swarm-scale 12"
echo "- Remover: ./bin/run_project.sh swarm-remove"
echo ""
echo "âœ… Teste do cluster concluÃ­do!"
echo "ğŸ’¡ Acesse http://localhost:8080 para ver o Spark Master UI" 
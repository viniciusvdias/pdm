# ConfiguraÃ§Ã£o do Cluster Apache Spark no Docker Swarm

## VisÃ£o Geral do Cluster

Este projeto foi otimizado para usar **todas as 4 mÃ¡quinas virtuais** do laboratÃ³rio PDM de forma distribuÃ­da. A configuraÃ§Ã£o atual maximiza o uso de recursos disponÃ­veis:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                             CLUSTER DOCKER SWARM (4 NÃ“DOS)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   VM01      â”‚   â”‚   VM02      â”‚   â”‚   VM03      â”‚   â”‚   VM04      â”‚                â”‚
â”‚  â”‚  (Manager)  â”‚   â”‚  (Worker)   â”‚   â”‚  (Worker)   â”‚   â”‚  (Worker)   â”‚                â”‚
â”‚  â”‚             â”‚   â”‚             â”‚   â”‚             â”‚   â”‚             â”‚                â”‚
â”‚  â”‚ Master      â”‚   â”‚ Workers     â”‚   â”‚ Workers     â”‚   â”‚ Workers     â”‚                â”‚
â”‚  â”‚ + 2 Workers â”‚   â”‚ (2x)        â”‚   â”‚ (2x)        â”‚   â”‚ (2x)        â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                                                         â”‚
â”‚                      TOTAL: 8 WORKERS DISTRIBUÃDOS                                     â”‚
â”‚                   Cada Worker: 4 cores, 12GB RAM                                       â”‚
â”‚                   Capacidade total: 32 cores, 96GB RAM                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Recursos Configurados

### **Por Worker:**

- **CPU**: 4 cores
- **RAM**: 12GB
- **Rede**: Otimizada para Docker Swarm
- **Armazenamento**: Volumes compartilhados

### **Driver (Master):**

- **CPU**: 2 cores
- **RAM**: 8GB
- **LocalizaÃ§Ã£o**: VM01 (Manager Node)

### **Capacidade Total:**

- **Workers**: 8 instÃ¢ncias distribuÃ­das
- **CPU Total**: 32 cores
- **RAM Total**: 96GB para executores + 8GB para driver
- **Paralelismo**: Otimizado para processamento distribuÃ­do

## InstruÃ§Ãµes de ConfiguraÃ§Ã£o

### PrÃ©-requisitos

1. **Docker Swarm jÃ¡ estÃ¡ configurado** no laboratÃ³rio com 4 nÃ³s
2. **VocÃª estÃ¡ logado na VM02** (node atual)
3. **O cluster jÃ¡ estÃ¡ ativo** conforme mostrado pelo `docker node ls`

### Passos para Deployment

#### 1. Clonar o Projeto

```bash
# Na VM02 (ou qualquer nÃ³ manager)
git clone <url-do-seu-repo>
cd g2
```

#### 2. Construir a Imagem

```bash
# Construir a imagem do projeto
./bin/run_project.sh build

# Ou diretamente:
docker build -t ru-ufla-analytics:latest .
```

#### 3. Fazer Deploy no Cluster

```bash
# Deploy completo no cluster Swarm
./bin/run_project.sh swarm-deploy
```

Este comando irÃ¡:

- Verificar se o Swarm estÃ¡ ativo
- Construir a imagem se necessÃ¡rio
- Fazer deploy da stack com 8 workers distribuÃ­dos
- Configurar rede overlay para comunicaÃ§Ã£o entre nÃ³s

#### 4. Verificar o Status

```bash
# Verificar status dos serviÃ§os
./bin/run_project.sh swarm-status

# Verificar nÃ³s do cluster
docker node ls

# Verificar serviÃ§os rodando
docker service ls
```

### Executando AnÃ¡lises

#### OpÃ§Ã£o 1: AnÃ¡lise AutomÃ¡tica (Recomendada)

```bash
# ExecuÃ§Ã£o completa automÃ¡tica
./bin/run_project.sh swarm-analyze complete

# AnÃ¡lise apenas com dados de amostra
./bin/run_project.sh swarm-analyze sample

# AnÃ¡lise de perÃ­odos especÃ­ficos
./bin/run_project.sh swarm-analyze complete 2024/1,2024/2
```

#### OpÃ§Ã£o 2: AnÃ¡lise Manual

```bash
# Criar job de anÃ¡lise manualmente
docker service create --name ru-analytics-job \
    --network ru-analytics_spark-network \
    --mount type=bind,source=$(pwd)/misc,destination=/app/misc \
    --mount type=bind,source=$(pwd)/datasample,destination=/app/datasample \
    --env SPARK_MASTER_URL=spark://spark-master:7077 \
    --env DOCKER_SWARM_MODE=true \
    --constraint 'node.role == manager' \
    --restart-condition none \
    ru-ufla-analytics:latest \
    /app/.venv/bin/python -m src.main analyze --master-url spark://spark-master:7077 --mode complete
```

## Monitoramento e Controle

### Interfaces Web

ApÃ³s o deploy, vocÃª pode acessar as interfaces web:

- **Spark Master UI**: http://localhost:8080
- **Spark Application UI**: http://localhost:4040 (durante execuÃ§Ã£o)
- **Workers UIs**: http://localhost:8081-8084

### Comandos de Monitoramento

```bash
# Ver logs do master
docker service logs -f ru-analytics_spark-master

# Ver logs dos workers
docker service logs -f ru-analytics_spark-worker

# Ver logs de um job especÃ­fico
docker service logs -f ru-analytics-job

# Status detalhado
./bin/run_project.sh swarm-status

# Escalar workers (se necessÃ¡rio)
./bin/run_project.sh swarm-scale 16  # Duplicar workers
```

### Escalabilidade

```bash
# Escalar para mais workers (mÃ¡ximo recomendado: 16)
./bin/run_project.sh swarm-scale 12

# Voltar para configuraÃ§Ã£o padrÃ£o
./bin/run_project.sh swarm-scale 8
```

## OtimizaÃ§Ãµes Implementadas

### 1. **ConfiguraÃ§Ãµes de Rede**

- Timeouts estendidos para cluster distribuÃ­do
- Heartbeat otimizado para latÃªncia de rede
- ConfiguraÃ§Ãµes RPC ajustadas

### 2. **GestÃ£o de Recursos**

- MemÃ³ria otimizada por executor (12GB)
- Cores balanceados (4 por worker)
- Garbage collection otimizado (G1GC)

### 3. **Paralelismo e Particionamento**

- Adaptive Query Execution habilitado
- Particionamento automÃ¡tico otimizado
- Skew join detection ativado

### 4. **TolerÃ¢ncia a Falhas**

- Retry configurado para clusters distribuÃ­dos
- Blacklist de nÃ³s problemÃ¡ticos
- Restart policies otimizadas

### 5. **SerializaÃ§Ã£o e Shuffle**

- Kryo serializer com configuraÃ§Ãµes otimizadas
- CompressÃ£o de shuffle habilitada
- Buffers aumentados para cluster

## Troubleshooting

### Problema: Workers nÃ£o conectam ao Master

```bash
# Verificar conectividade de rede
docker service ls
docker service ps ru-analytics_spark-worker --no-trunc

# Recriar serviÃ§os se necessÃ¡rio
./bin/run_project.sh swarm-remove
./bin/run_project.sh swarm-deploy
```

### Problema: Performance baixa

```bash
# Verificar distribuiÃ§Ã£o de workers
docker service ps ru-analytics_spark-worker

# Verificar logs para gargalos
docker service logs ru-analytics_spark-master

# Ajustar recursos se necessÃ¡rio
./bin/run_project.sh swarm-scale 12
```

### Problema: MemÃ³ria insuficiente

```bash
# Verificar uso de recursos
docker stats

# Ajustar configuraÃ§Ãµes de memÃ³ria no docker-compose.swarm.yml
# Reduzir SPARK_EXECUTOR_MEMORY se necessÃ¡rio
```

## Limpeza e RemoÃ§Ã£o

```bash
# Remover stack completa
./bin/run_project.sh swarm-remove

# Remover imagens nÃ£o utilizadas
docker image prune -f

# Remover volumes nÃ£o utilizados
docker volume prune -f
```

## ConfiguraÃ§Ãµes AvanÃ§adas

### Ajuste de Performance

Para ajustar a performance, edite o arquivo `docker-compose.swarm.yml`:

```yaml
environment:
  - SPARK_EXECUTOR_MEMORY=16g # Aumentar se hÃ¡ RAM disponÃ­vel
  - SPARK_EXECUTOR_CORES=6 # Aumentar se hÃ¡ CPU disponÃ­vel
  - SPARK_EXECUTOR_INSTANCES=12 # Aumentar nÃºmero de workers
```

### Monitoramento Detalhado

```bash
# CPU e memÃ³ria por container
docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"

# Logs especÃ­ficos por serviÃ§o
docker service logs --tail 100 ru-analytics_spark-worker

# Inspect de serviÃ§os
docker service inspect ru-analytics_spark-worker
```

## Resumo dos Comandos Principais

| Comando                                       | DescriÃ§Ã£o                  |
| --------------------------------------------- | -------------------------- |
| `./bin/run_project.sh swarm-deploy`           | Deploy completo no cluster |
| `./bin/run_project.sh swarm-analyze complete` | Executar anÃ¡lise completa  |
| `./bin/run_project.sh swarm-status`           | Ver status do cluster      |
| `./bin/run_project.sh swarm-scale 12`         | Escalar workers            |
| `./bin/run_project.sh swarm-remove`           | Remover stack              |
| `./bin/run_project.sh swarm-logs`             | Ver logs                   |

---

**ğŸš€ Agora vocÃª tem um cluster Apache Spark distribuÃ­do usando todos os recursos das 4 VMs do laboratÃ³rio!**

**ğŸ’¡ Capacidade total: 32 cores, 96GB RAM para processamento distribuÃ­do de Big Data**

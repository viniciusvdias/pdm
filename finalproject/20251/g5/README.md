# Relat√≥rio Final do Projeto: *Processamento de Dados Musicais do Spotify com PySpark*
## 1. Contexto e motiva√ß√£o

Nos √∫ltimos anos, com o crescimento de plataformas de streaming como o Spotify, uma enorme quantidade de dados musicais passou a ser gerada, incluindo letras, metadados, m√©tricas de √°udio e classifica√ß√µes emocionais. Esse volume de dados abre oportunidades para an√°lises em larga escala sobre padr√µes lingu√≠sticos, sentimentos e rela√ß√µes entre linguagem e m√∫sica.

O objetivo principal deste projeto √© analisar e processar letras de m√∫sicas em escala utilizando ferramentas de Big Data, em particular Apache Spark, com foco em:

- Identificar as palavras mais associadas a diferentes emo√ß√µes musicais

- Avaliar a distribui√ß√£o e frequ√™ncia dessas palavras em um corpus massivo

- Otimizar o processamento atrav√©s de formato Parquet e execu√ß√£o distribu√≠da

O projeto utiliza um dataset real com aproximadamente 500 mil m√∫sicas (extra√≠do do Spotify), com atributos como g√™nero, artista, letra e emo√ß√£o associada, o que seria invi√°vel de processar eficientemente com ferramentas tradicionais.

Al√©m disso, o trabalho prop√µe uma infraestrutura distribu√≠da replic√°vel via Docker Swarm, simulando um cluster Spark com m√∫ltiplos n√≥s, de forma pr√°tica e port√°til, permitindo testar desempenho, escalabilidade e custo computacional em diferentes configura√ß√µes.

## 2. Dados üéß

Este projeto utiliza o dataset ‚Äú500K+ Spotify Songs with Lyrics,Emotions & More‚Äù, dispon√≠vel publicamente no Kaggle:

üîó Fonte oficial: https://www.kaggle.com/datasets/devdope/900k-spotify

### 2.1 **O que o dataset cont√©m**:
- Aproximadamente 500 mil registros de m√∫sicas
- Cada linha representa uma m√∫sica e seus dados
- Tamanho aproximado: 1,3 GB
- Est√° dispon√≠vel nos formatos .csv e .json
- S√£o 39 colunas com atributos como:
    - Nome da m√∫sica, artista, √°lbum, g√™nero, data de lan√ßamento
    - Letra completa da m√∫sica
    - Emo√ß√£o da m√∫sica (campo emotion) associada √† letra
    - Caracter√≠sticas T√©cnicas e popularidade da m√∫sica
    - Indicadores de Atmosfera Musical (energia, positividade, dan√ßa, ac√∫stica, instrumentalidade etc.)
    - Usos Sugeridos para a Faixa (Good for Party, Good for Work, etc)
    - Indica√ß√µes por Similaridade Sonora

### 2.2 Como obter os dados

Para baixar e extrair os dados do projeto entre no site do kaggle https://www.kaggle.com/datasets/devdope/900k-spotify e fa√ßa o download do zip do dataset, ou siga os passos abaixo:

1. Baixe o arquivo zip do dataset usando a API do Kaggle:
 ```bash
curl -L -o 500k-spotify.zip \
https://www.kaggle.com/api/v1/datasets/download/devdope/900k-spotify
```
2. Extraia o conte√∫do do arquivo zip:
```bash
unzip 500k-spotify.zip
```
3. Ap√≥s a extra√ß√£o, um dos arquivos dispon√≠veis ser√° `spotify_dataset.csv` que foi usado no presente projeto

## 3. Como rodar o projeto

1. Clone o reposit√≥rio do projeto
2. Acesse a branch do grupo e a a pasta do projeto do grupo
```bash
git checkout finalproject-20251-G5

cd finalproject/20251/g5
```
3. Execute o script de configura√ß√£o inicial e ative as configura√ß√µes no terminal
```bash
./bin/pdmtf setup
source ~/.bashrc
pdmtf
```
### ‚öôÔ∏è **Inicializa√ß√£o do ambiente com Docker Swarm**

1. Acesse a pasta `src` do projeto para rodar os comandos `pdmtf`
```bash
cd src
```
2. Inicie os servi√ßos Spark com Jupyter usando Docker Swarm, esse comando sobe os servi√ßos: Jupyter Notebook, Spark Master e Spark Worker
```bash
pdmtf init
```
3. Execute um `docker ps` para verificar se o containers est√£o ativos e acesse a interface web em `http://localhost:8888/lab?token=spark123`

4. Execute `pdmtf help` para visualizar outros comandos dispon√≠veis como `pdmtf stop` (Parar o cluster Spark) ou `pdmtf scale 3` (Alterar o n√∫mero de workers)

### 3.1 Quick start (usando uma amostra de dados em `datasample/`)
1. Fa√ßa uma copia do dataset de exemplo `spotify_dataset.csv` presente do diret√≥rio `/datasample` ao diret√≥rio `src/spark-data`
2. Acesse `http://localhost:8888/lab?token=spark123`
3. Fa√ßa o pr√©-processamento dos dados executando os notebooks:
   - csv_to_parquet.ipynb
   - tratamento_full_dataset.ipynb 

4. Para rodar os workloads, execute os notebooks:
   - workload_1.ipynb
   - workload_2.ipynb
   - workload_3.ipynb

### 3.2 Como rodar com todo o dataset

1. Utilize o csv baixado no passo 2.2 e coloque esse arquivo `spotify_dataset.csv` no diret√≥rio `src/spark-data`
2. Acesse `http://localhost:8888/lab?token=spark123`
3. Fa√ßa o pr√©-processamento dos dados executando os notebooks:
   - csv_to_parquet.ipynb
   - tratamento_full_dataset.ipynb 

4. Para rodar os workloads, execute os notebooks:
   - workload_1.ipynb
   - workload_2.ipynb
   - workload_3.ipynb


## 4. Arquitetura do projeto

O projeto utiliza cont√™ineres orquestrados com Docker Swarm para processar dados com Apache Spark e interagir via Jupyter Notebook. Seus principais componentes s√£o:

- **Usu√°rio (navegador web):** Acessa a interface do Jupyter Notebook em `http://localhost:8888` para escrever e executar scripts PySpark. O navegador n√£o integra o cluster, mas √© o ponto de entrada para o usu√°rio.

- **Jupyter Notebook (Spark Driver):** Executado em um cont√™iner, fornece a interface web e atua como Spark Driver. Inicia a SparkSession e envia os jobs para o cluster via `spark://spark-master:7077`. Compartilha o volume /spark-data com os demais servi√ßos.

- **Spark Master:** Coordena o cluster, recebendo jobs do Driver e distribuindo-os entre os Workers. Roda em cont√™iner pr√≥prio e exp√µe sua interface de monitoramento em `http://localhost:8080`.

- **Spark Workers:** Executam as tarefas de forma distribu√≠da. Conectam-se automaticamente ao Master e acessam o volume /spark-data para leitura e escrita. S√£o cont√™ineres escal√°veis no Docker Swarm.

- **Volume /spark-data:** Pasta compartilhada entre todos os cont√™ineres, usada para armazenar dados de entrada (.csv) e sa√≠da (.parquet). Elimina a necessidade de transfer√™ncia via rede.

- **Rede spark-net:** Interliga todos os cont√™ineres, permitindo comunica√ß√£o entre os servi√ßos.

<p align="center">
  <img src="presentation/arquitetura-big.png" alt="Texto alternativo" width="700"/>
</p>

- Fluxo de Dados:

  ```
  [CSV] ‚Üí [Transforma√ß√£o Parquet] ‚Üí [Limpeza] ‚Üí [Processamento] ‚Üí [Resultados]
  ```



## 5. Workloads evaluated

#### [WORKLOAD-1] Agrupamento de letras de m√∫sicas por emo√ß√£o

**Objetivo:** Mostrar quais palavras s√£o mais frequentes nas letras das m√∫sicas em cada emo√ß√£o.

**Etapas:**
- Leitura do dataset no formato Parquet.
- Remo√ß√£o de pontua√ß√£o e s√≠mbolos usando `regex_replace`.
- Remo√ß√£o de StopWords (palavras sem sentido sem√¢ntico).
- Tokeniza√ß√£o por espa√ßos.
- Convers√£o para min√∫sculas.
- Explos√£o das palavras em linhas individuais usando `explode`.
- Ranqueamento de palavras mais recorrentes por emo√ß√£o.

---

#### [WORKLOAD-2] C√°lculo da Similaridade de Jaccard

**Objetivo:** Comparar todos os pares poss√≠veis de artistas dentro do mesmo g√™nero utilizando a m√©trica de Jaccard com base no vocabul√°rio textual.

**Etapas:**
- Realiza√ß√£o de um self-join (cruzamento) entre os artistas por g√™nero.
- C√°lculo de interse√ß√£o (`array_intersect`) e uni√£o (`array_union`) de vocabul√°rios.
- C√°lculo da similaridade de Jaccard: `interse√ß√£o / uni√£o`.
- Ranqueamento dos pares mais similares por g√™nero.

---

#### [WORKLOAD-3] Similaridade L√©xica entre G√™neros Musicais

**Objetivo:** Encontrar o n√∫mero de palavras em comum entre os principais g√™neros musicais, medindo similaridade l√©xica.

**Etapas**:

- Leitura do dataset `musicas_limpas.parquet`.
- Sele√ß√£o dos 10 g√™neros musicais com mais m√∫sicas no dataset.
- Explos√£o das palavras com `explode` e `split`.
- Agrupamento por `main_genre` usando `collect_set("palavra")` para obter vocabul√°rio √∫nico por g√™nero.
- Self-join do vocabul√°rio de g√™neros usando `crossJoin`, comparando pares distintos (`g1 < g2`).
- C√°lculo do n√∫mero de palavras em comum por par de g√™neros usando `array_intersect` + `size`.
- Ordena√ß√£o decrescente pelo n√∫mero de palavras em comum.

---

- Specify each big data task evaluated in your project (queries, data pre-processing, sub-routines, etc.).
- Be specific: describe the details of each workload, and give each a clear name. These named workloads will be referenced and evaluated via performance experiments in the next section.
  - Example: [WORKLOAD-1] Query that computes the average occupation within each
    time window (include query below). [WORKLOAD-2] Preprocessing, including
  removing duplicates, standardization, etc.

---

## 6. Experiments and results

### 6.1 Experimental environment

- As execu√ß√µes foram realizadas em ambiente Docker com Spark.
- Os experimentos foram realizados em uma m√°quina:
> Windows 11
> Ubuntu 22.04 (containers)
> Docker Version 28.3.0
> Spark Version 3.4.1
> Modo Cluster
> 1 Spark Master + N workers (var√≠avel)
> CPU 3.70 Ghz base (at√© 4.6 Ghz)
> 16 GB de RAM DDR4 3200 MHz

### 6.2 What did you test?

Foram avaliadas as seguintes varia√ß√µes de configura√ß√£o:

| Par√¢metro                 | Valores Testados              |
|--------------------------|-------------------------------|
| Workers                  | 1, 2, 6                        |
| N√∫cleos por Worker       | 1, 2, 6                        |
| M√©tricas observadas      | Tempo total (s), uso de mem√≥ria, distribui√ß√£o de tarefas, uso de CPU, Throughput (MB/s) |
| Repeti√ß√µes               | 3 execu√ß√µes por configura√ß√£o   |

### 6.3 Results
#### Tabela Comparativa por Configura√ß√£o
 Todas as execu√ß√µes foram feitas no mesmo arquivo parquet de 424 MB

### Workload 1 - Agrupamento de letras de m√∫sicas por emo√ß√£o

| WORKERS | CORES | TEMPO (s) | Throughput (MB/s) |
|---------|-------|-----------|------------|
| 1       | 1     | 163       | 2.59       |
| 2       | 1     | 106       | 3.99       |
| 4       | 1     | 74        | 5.72       |
| 6       | 1     | 63        | 6.74       |
| 8       | 1     | 61        | 6.90       |
| 16      | 1     | 53        | 7.82       |


---

### Workload 2 - C√°lculo da Similaridade de Jaccard

| WORKERS | CORES | TEMPO (s) | Throughput (MB/s) |
|---------|-------|-----------|------------|
| 1       | 1     | 91        | 4.66       |
| 1       | 6     | 49        | 8.65       |
| 2       | 2     | 70        | 6.06       |
| 6       | 1     | 59        | 7.19       |
| 6       | 6     | 46        | 9.22       |

---

### Workload 3 - Similaridade L√©xica entre G√™neros Musicais

| WORKERS | CORES | TEMPO (s) | Throughput (MB/s) |
|---------|-------|-----------|------------|
| 1       | 1     | 269       | 1.58       |
| 1       | 6     | 122       | 3.48       |
| 2       | 2     | 116       | 4.66       |
| 6       | 1     | 163       | 2.60       |
| 6       | 6     | 105       | 4.04       |

---

## 7. Discussion and Conclusions

### O que funcionou bem:

- A arquitetura com **Apache Spark em Docker Swarm** se mostrou eficiente e escal√°vel para os workloads propostos.
- Os workloads principais conseguiram demonstrar claramente os ganhos de paralelismo ao aumentar o n√∫mero de workers e n√∫cleos.
- As opera√ß√µes mais custosas computacionalmente (como `crossJoin` e `array_intersect`) foram bem distribu√≠das no cluster com a configura√ß√£o adequada de particionamento (`spark.sql.shuffle.partitions`).
- A utiliza√ß√£o do m√©todo `cache()` em pontos estrat√©gicos (como o vocabul√°rio pr√©-computado) evitou recomputa√ß√µes dispendiosas e otimizou o tempo final.
- O workload intermedi√°rio que calcula interse√ß√µes entre g√™neros diferentes (sem filtragem por g√™nero) tamb√©m for√ßou um bom estresse no cluster, atingindo milhares de combina√ß√µes.
- As an√°lises mostraram que a distribui√ß√£o de tarefas foi mais eficiente em configura√ß√µes com m√∫ltiplos workers e m√∫ltiplos n√∫cleos (como 6 workers √ó 6 cores).

### O que n√£o funcionou ou teve limita√ß√µes:

- Workloads aparentemente pesados tiveram performance surpreendentemente leve. Isso se deve ao pequeno n√∫mero de combina√ß√µes poss√≠veis, tornando a opera√ß√£o leve para o cluster.
- Inicialmente, n√£o havia particionamento adequado definido em algumas opera√ß√µes com janela (`Window`), o que gerava **`WARN WindowExec: No Partition Defined`** e resultava em reagrupamento de todos os dados em uma √∫nica parti√ß√£o, prejudicando a paraleliza√ß√£o.
- A performance foi limitada em alguns testes pelo uso de limites de recursos (CPU/mem√≥ria) definidos no `docker-compose.yml`, o que afetou muito o desempenho.
- O `repartition()` s√≥ surtiu efeito vis√≠vel em workloads intensos e em joins com grandes cardinalidades.

### Desafios encontrados:

- Garantir o balanceamento do workload entre os workers, visto que a simples defini√ß√£o de parti√ß√µes nem sempre resultava em uso igualit√°rio dos recursos.
- Entender e validar visualmente (via UI do Spark) se os workers estavam realmente processando dados e n√£o apenas o driver.
- Reproduzir experimentos de forma consistente exigiu controle rigoroso do ambiente (vers√£o do Docker, rein√≠cio dos containers, cache clean).

## 8. References and External Resources

### Bibliotecas e Frameworks

- [Apache Spark](https://spark.apache.org/) ‚Äî processamento distribu√≠do de dados.
- [PySpark API](https://spark.apache.org/docs/latest/api/python/) ‚Äî interface Python para Apache Spark.
- [Docker](https://www.docker.com/) ‚Äî conteineriza√ß√£o do ambiente.
- [Docker Compose](https://docs.docker.com/compose/) ‚Äî orquestra√ß√£o local de containers.
- [Spark UI](https://spark.apache.org/docs/latest/web-ui.html) ‚Äî ferramenta visual para monitoramento.

### Dataset

- Dataset Utilizado - [Spotify Dataset](https://www.kaggle.com/datasets/devdope/900k-spotify?select=final_milliondataset_BERT_500K_revised.json)
- Total de registros: milhares de m√∫sicas com metadados como artista, g√™nero, letra e emo√ß√µes.
- Transformado em `.parquet` para leitura otimizada no cluster.

### Inspira√ß√µes e fontes de consulta

- [Spark Optimization Guide](https://spark.apache.org/docs/latest/sql-performance-tuning.html)
- Stack Overflow e f√≥runs sobre uso de `array_intersect`, joins cruzados e tuning de `Window` no Spark.
- Documenta√ß√µes de `repartition`, `cache`, `join hints` e `crossJoin` no contexto do PySpark.


*Esse relat√≥rio foi desenvolvido com base em testes pr√°ticos, medi√ß√µes diretas via tempo de execu√ß√£o e inspe√ß√£o da interface web do Spark em ambiente distribu√≠do via Docker Swarm.*

---
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f078bf-905a-4f4c-966a-299e31561ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/09 03:50:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao Spark master: spark://spark-master:7077\n"
     ]
    }
   ],
   "source": [
    "# 1. Criar SparkSession\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import socket\n",
    "\n",
    "local_ip = socket.gethostbyname(socket.gethostname())\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Palavras por Emoção\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.driver.host\", local_ip) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Conectado ao Spark master:\", spark.sparkContext.master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b6a958-d3e1-45bc-8793-1b63c60fdd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso\n"
     ]
    }
   ],
   "source": [
    "# 2. Ler o dataset Parquet\n",
    "\n",
    "df = spark.read.parquet(\"/spark-data/musicas_limpas_cluster.parquet\")\n",
    "\n",
    "print(f\"Sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e79828-2eac-4e65-81e3-1ec6b32a1103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso\n"
     ]
    }
   ],
   "source": [
    "# 3. Tokenizar as letras\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"tokens\", pattern=\"\\\\W\")\n",
    "df_tokens = tokenizer.transform(df)\n",
    "\n",
    "print(f\"Sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb3db1d-bb04-4636-8909-d21953c84b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso\n"
     ]
    }
   ],
   "source": [
    "# 4. Remover StopWords\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "# Lista customizada de palavras irrelevantes\n",
    "custom_stopwords = [\n",
    "    \"like\", \"yeah\", \"got\", \"get\", \"uh\", \"la\", \"na\", \"da\", \"ooh\", \"ah\", \"woo\", \"go\", \"ll\",\n",
    "    \"hey\", \"yo\", \"uhh\", \"uhuh\", \"gonna\", \"wanna\", \"baby\", \"oh\", \"whoa\", \"know\", \"re\", \"chorus\",\n",
    "    \"ain\", \"let\", \"ve\", \"one\", \"verse\", \"cause\", \"m\"\n",
    "]\n",
    "\n",
    "# Juntar com stopwords padrão do inglês\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_filtrados\")\n",
    "remover.setStopWords(remover.getStopWords() + custom_stopwords)\n",
    "\n",
    "df_tokens = remover.transform(df_tokens)\n",
    "\n",
    "print(f\"Sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4600dc8f-cf91-471a-9f25-7ce1aa1e1cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso\n"
     ]
    }
   ],
   "source": [
    "# 5. Explodir tokens para que cada palavra seja uma linha e contar occorências\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, desc\n",
    "\n",
    "df_exploded = df_tokens.select(\"emotion_lower\", explode(\"tokens_filtrados\").alias(\"palavra\"))\n",
    "\n",
    "df_freq = df_exploded.groupBy(\"palavra\", \"emotion_lower\").count()\n",
    "\n",
    "window_word = Window.partitionBy(\"palavra\").orderBy(desc(\"count\"))\n",
    "\n",
    "df_unique_emotion = df_freq.withColumn(\"rank\", row_number().over(window_word)) \\\n",
    "                           .filter(\"rank == 1\") \\\n",
    "                           .drop(\"rank\")\n",
    "\n",
    "print(f\"Sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00851275-de60-4e5c-a8f0-33ac13eba277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42bb3219-09b4-40c8-a1b2-ca1a48c55ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso\n"
     ]
    }
   ],
   "source": [
    "# 6. Agrupar por emoção + palavra\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, desc\n",
    "\n",
    "window_emotion = Window.partitionBy(\"emotion_lower\").orderBy(desc(\"count\"))\n",
    "\n",
    "df_top_words = df_unique_emotion.withColumn(\"rank\", row_number().over(window_emotion)) \\\n",
    "                                .filter(\"rank <= 5\")\n",
    "\n",
    "print(f\"Sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e9c1214-33aa-491e-9602-e7d7b6ad9a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo: 0.19 segundos\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "print(f\"Tempo: {end_time - start_time:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc1f760-e7f6-4561-bb3a-24dcc0dead99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:===========================================>          (160 + 1) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+------+----+\n",
      "|emotion_lower|palavra  |count |rank|\n",
      "+-------------+---------+------+----+\n",
      "|anger        |nigga    |159591|1   |\n",
      "|anger        |bitch    |149983|2   |\n",
      "|anger        |fuck     |141322|3   |\n",
      "|anger        |shit     |140379|4   |\n",
      "|anger        |niggas   |120800|5   |\n",
      "|fear         |scared   |9130  |1   |\n",
      "|fear         |afraid   |9127  |2   |\n",
      "|fear         |strange  |4833  |3   |\n",
      "|fear         |worried  |2315  |4   |\n",
      "|fear         |nervous  |2104  |5   |\n",
      "|joy          |love     |311506|1   |\n",
      "|joy          |see      |191572|2   |\n",
      "|joy          |time     |184364|3   |\n",
      "|joy          |never    |176742|4   |\n",
      "|joy          |want     |173612|5   |\n",
      "|love         |loving   |11990 |1   |\n",
      "|love         |longing  |1920  |2   |\n",
      "|love         |naughty  |1902  |3   |\n",
      "|love         |loyal    |1737  |4   |\n",
      "|love         |tender   |1723  |5   |\n",
      "|sadness      |away     |91410 |1   |\n",
      "|sadness      |heart    |83310 |2   |\n",
      "|sadness      |alone    |62525 |3   |\n",
      "|sadness      |gone     |55361 |4   |\n",
      "|sadness      |home     |55081 |5   |\n",
      "|surprise     |amazed   |854   |1   |\n",
      "|surprise     |impressed|575   |2   |\n",
      "|surprise     |dazed    |354   |3   |\n",
      "|surprise     |chorky   |133   |4   |\n",
      "|surprise     |stunned  |110   |5   |\n",
      "+-------------+---------+------+----+\n",
      "\n",
      "Tempo de execução: 133.52 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "df_top_words.unpersist()\n",
    "df_top_words.persist()\n",
    "# 7. Obter o top 5 palavras mais frequentes por emoção\n",
    "df_top_words.select(\"emotion_lower\", \"palavra\", \"count\", \"rank\") \\\n",
    "            .orderBy(\"emotion_lower\", \"rank\") \\\n",
    "            .show(100, truncate=False)\n",
    "\n",
    "fim = time.time()\n",
    "\n",
    "duracao = fim - inicio\n",
    "throughput = 424/duracao\n",
    "\n",
    "print(f\"\\n--- Análise de Desempenho ---\")\n",
    "print(f\"Tempo total de execução: {duracao:.2f} segundos\")\n",
    "print(f\"Throughput da execução: {throughput:.2f} MB/s\")\n",
    "print(f\"----------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

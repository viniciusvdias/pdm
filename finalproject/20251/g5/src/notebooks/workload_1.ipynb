{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f078bf-905a-4f4c-966a-299e31561ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/09 22:23:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao Spark master: spark://spark-master:7077\n"
     ]
    }
   ],
   "source": [
    "# 1. Criar SparkSession\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import socket\n",
    "\n",
    "local_ip = socket.gethostbyname(socket.gethostname())\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Palavras por Emoção\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.driver.host\", local_ip) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Conectado ao Spark master:\", spark.sparkContext.master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b6a958-d3e1-45bc-8793-1b63c60fdd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso\n"
     ]
    }
   ],
   "source": [
    "# 2. Ler o dataset Parquet\n",
    "\n",
    "df = spark.read.parquet(\"/spark-data/musicas_limpas.parquet\")\n",
    "\n",
    "print(f\"Sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e79828-2eac-4e65-81e3-1ec6b32a1103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso\n"
     ]
    }
   ],
   "source": [
    "# 3. Tokenizar as letras\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"tokens\", pattern=\"\\\\W\")\n",
    "df_tokens = tokenizer.transform(df)\n",
    "\n",
    "print(f\"Sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb3db1d-bb04-4636-8909-d21953c84b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso\n"
     ]
    }
   ],
   "source": [
    "# 4. Remover StopWords\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "# Lista customizada de palavras irrelevantes\n",
    "custom_stopwords = [\n",
    "    \"like\", \"yeah\", \"got\", \"get\", \"uh\", \"la\", \"na\", \"da\", \"ooh\", \"ah\", \"woo\", \"go\", \"ll\",\n",
    "    \"hey\", \"yo\", \"uhh\", \"uhuh\", \"gonna\", \"wanna\", \"baby\", \"oh\", \"whoa\", \"know\", \"re\", \"chorus\",\n",
    "    \"ain\", \"let\", \"ve\", \"one\", \"verse\", \"cause\", \"m\"\n",
    "]\n",
    "\n",
    "# Juntar com stopwords padrão do inglês\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_filtrados\")\n",
    "remover.setStopWords(remover.getStopWords() + custom_stopwords)\n",
    "\n",
    "df_tokens = remover.transform(df_tokens)\n",
    "\n",
    "print(f\"Sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4600dc8f-cf91-471a-9f25-7ce1aa1e1cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso\n"
     ]
    }
   ],
   "source": [
    "# 5. Explodir tokens para que cada palavra seja uma linha e contar occorências\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, desc\n",
    "\n",
    "df_exploded = df_tokens.select(\"emotion_lower\", explode(\"tokens_filtrados\").alias(\"palavra\"))\n",
    "\n",
    "df_freq = df_exploded.groupBy(\"palavra\", \"emotion_lower\").count()\n",
    "\n",
    "window_word = Window.partitionBy(\"palavra\").orderBy(desc(\"count\"))\n",
    "\n",
    "df_unique_emotion = df_freq.withColumn(\"rank\", row_number().over(window_word)) \\\n",
    "                           .filter(\"rank == 1\") \\\n",
    "                           .drop(\"rank\")\n",
    "\n",
    "print(f\"Sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00851275-de60-4e5c-a8f0-33ac13eba277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42bb3219-09b4-40c8-a1b2-ca1a48c55ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso\n"
     ]
    }
   ],
   "source": [
    "# 6. Agrupar por emoção + palavra\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, desc\n",
    "\n",
    "window_emotion = Window.partitionBy(\"emotion_lower\").orderBy(desc(\"count\"))\n",
    "\n",
    "df_top_words = df_unique_emotion.withColumn(\"rank\", row_number().over(window_emotion)) \\\n",
    "                                .filter(\"rank <= 5\")\n",
    "\n",
    "print(f\"Sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e9c1214-33aa-491e-9602-e7d7b6ad9a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo: 0.10 segundos\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "print(f\"Tempo: {end_time - start_time:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc1f760-e7f6-4561-bb3a-24dcc0dead99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:===================================================>  (192 + 1) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+-----+----+\n",
      "|emotion_lower|palavra |count|rank|\n",
      "+-------------+--------+-----+----+\n",
      "|anger        |bitch   |631  |1   |\n",
      "|anger        |nigga   |548  |2   |\n",
      "|anger        |fuck    |421  |3   |\n",
      "|anger        |shit    |373  |4   |\n",
      "|anger        |niggas  |334  |5   |\n",
      "|fear         |number  |38   |1   |\n",
      "|fear         |mistake |37   |2   |\n",
      "|fear         |strange |37   |3   |\n",
      "|fear         |llama   |31   |4   |\n",
      "|fear         |spoken  |30   |5   |\n",
      "|joy          |love    |453  |1   |\n",
      "|joy          |come    |313  |2   |\n",
      "|joy          |never   |302  |3   |\n",
      "|joy          |see     |297  |4   |\n",
      "|joy          |want    |294  |5   |\n",
      "|love         |somebody|58   |1   |\n",
      "|love         |ay      |35   |2   |\n",
      "|love         |lovely  |33   |3   |\n",
      "|love         |loves   |28   |4   |\n",
      "|love         |fever   |23   |5   |\n",
      "|sadness      |still   |192  |1   |\n",
      "|sadness      |feel    |190  |2   |\n",
      "|sadness      |away    |180  |3   |\n",
      "|sadness      |night   |159  |4   |\n",
      "|sadness      |gone    |158  |5   |\n",
      "|surprise     |clone   |22   |1   |\n",
      "|surprise     |fridge  |19   |2   |\n",
      "|surprise     |melanie |18   |3   |\n",
      "|surprise     |changing|10   |4   |\n",
      "|surprise     |snitches|10   |5   |\n",
      "+-------------+--------+-----+----+\n",
      "\n",
      "\n",
      "--- Análise de Desempenho ---\n",
      "Tempo total de execução: 15.74 segundos\n",
      "Throughput da execução: 26.93 MB/s\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "df_top_words.unpersist()\n",
    "df_top_words.persist()\n",
    "# 7. Obter o top 5 palavras mais frequentes por emoção\n",
    "df_top_words.select(\"emotion_lower\", \"palavra\", \"count\", \"rank\") \\\n",
    "            .orderBy(\"emotion_lower\", \"rank\") \\\n",
    "            .show(100, truncate=False)\n",
    "\n",
    "fim = time.time()\n",
    "\n",
    "duracao = fim - inicio\n",
    "throughput = 424/duracao\n",
    "\n",
    "print(f\"\\n--- Análise de Desempenho ---\")\n",
    "print(f\"Tempo total de execução: {duracao:.2f} segundos\")\n",
    "print(f\"Throughput da execução: {throughput:.2f} MB/s\")\n",
    "print(f\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1820f3e2-f57f-4f61-a4fe-5a0d04740d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e3bfe-cea5-4d43-b786-f61af1382c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "905611ce-4158-40e4-b317-316556e555c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/09 20:55:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session iniciada com sucesso!\n",
      "Iniciando a execução do Workload Final de Estresse...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etapa 1/4: Criando vocabulário por artista...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário criado para 114163 artistas.\n",
      "Etapa 2/4: Realizando cross-join e calculando similaridade (esta etapa pode demorar)...\n",
      "Etapa 3/4: Ranqueando os resultados...\n",
      "Etapa 4/4: Salvando os resultados...\n",
      "Workload concluído. Top 100 resultados\n",
      "\n",
      "--- Análise de Desempenho ---\n",
      "Tempo total de execução: 53.17 segundos\n",
      "Throughput da execução: 7.98 MB/s\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, explode, lower, regexp_replace, collect_set, size, array_intersect, array_union, lit, when\n",
    "from pyspark.sql.window import Window\n",
    "import socket\n",
    "import time\n",
    "\n",
    "# --- Configuração do Spark Session ---\n",
    "local_ip = socket.gethostbyname(socket.gethostname())\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Workload Final - Similaridade Jaccard de Artistas\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Session iniciada com sucesso!\")\n",
    "\n",
    "def executar_workload_final():\n",
    "    \"\"\"\n",
    "    Executa um workload de estresse para encontrar os pares de artistas mais similares\n",
    "    dentro dos principais gêneros, usando a Similaridade Jaccard.\n",
    "    \"\"\"\n",
    "    # --- 1. Carregar e Preparar os Dados ---\n",
    "    caminho_parquet = \"/spark-data/musicas_limpas_cluster.parquet\"\n",
    "    df = spark.read.parquet(caminho_parquet)\n",
    "\n",
    "    # Filtra para os 5 gêneros mais populares para o teste. Aumentar este número aumenta drasticamente a carga.\n",
    "    top_genres = [row['main_genre'] for row in df.groupBy(\"main_genre\").count().orderBy(col(\"count\").desc()).limit(5).collect()]\n",
    "    df_filtrado = df.filter(col(\"main_genre\").isin(top_genres))\n",
    "\n",
    "    # --- 2. Processamento e Agregação de Palavras por Artista ---\n",
    "    print(\"Etapa 1/4: Criando vocabulário por artista...\")\n",
    "    df_palavras = df_filtrado.withColumn(\"palavra\", explode(split(lower(regexp_replace(col(\"text\"), r'[\\W_]+', ' ')), ' '))) \\\n",
    "                             .select(\"main_genre\", \"Artist(s)\", \"palavra\") \\\n",
    "                             .filter(col(\"palavra\") != \"\")\n",
    "\n",
    "    df_vocabulario_artista = df_palavras.groupBy(\"main_genre\", \"Artist(s)\").agg(collect_set(\"palavra\").alias(\"vocabulario\"))\n",
    "    \n",
    "    # O cache é crucial aqui para evitar que o Spark recalcule o vocabulário a cada iteração do join.\n",
    "    df_vocabulario_artista.cache()\n",
    "    print(f\"Vocabulário criado para {df_vocabulario_artista.count()} artistas.\")\n",
    "\n",
    "    # --- 3. Self-Join e Cálculo da Similaridade Jaccard (A PARTE MAIS PESADA) ---\n",
    "    print(\"Etapa 2/4: Realizando cross-join e calculando similaridade (esta etapa pode demorar)...\")\n",
    "    df_a1 = df_vocabulario_artista.alias(\"a1\")\n",
    "    df_a2 = df_vocabulario_artista.alias(\"a2\")\n",
    "\n",
    "    # Realiza o join para criar pares de artistas distintos DENTRO do mesmo gênero\n",
    "    df_pares_artistas = df_a1.join(\n",
    "        df_a2,\n",
    "        (col(\"a1.main_genre\") == col(\"a2.main_genre\")) & (col(\"a1.`Artist(s)`\") < col(\"a2.`Artist(s)`\")),\n",
    "        \"inner\"\n",
    "    )\n",
    "\n",
    "    # Calcula a interseção e a união para cada par\n",
    "    df_jaccard = df_pares_artistas.withColumn(\n",
    "        \"intersecao\",\n",
    "        size(array_intersect(col(\"a1.vocabulario\"), col(\"a2.vocabulario\")))\n",
    "    ).withColumn(\n",
    "        \"uniao\",\n",
    "        size(array_union(col(\"a1.vocabulario\"), col(\"a2.vocabulario\")))\n",
    "    ).withColumn(\n",
    "        \"similaridade_jaccard\",\n",
    "        # Evita divisão por zero se a união for 0\n",
    "        when(col(\"uniao\") == 0, 0.0).otherwise(col(\"intersecao\") / col(\"uniao\"))\n",
    "    )\n",
    "\n",
    "    # --- 4. Encontrar os Pares Mais Similares por Gênero ---\n",
    "    print(\"Etapa 3/4: Ranqueando os resultados...\")\n",
    "    window_spec = Window.partitionBy(col(\"a1.main_genre\")).orderBy(col(\"similaridade_jaccard\").desc())\n",
    "    \n",
    "    df_resultado = df_jaccard.withColumn(\"rank\", col(\"intersecao\").desc()) \\\n",
    "                             .select(\n",
    "                                 col(\"a1.main_genre\").alias(\"genero\"),\n",
    "                                 col(\"a1.`Artist(s)`\").alias(\"artista_1\"),\n",
    "                                 col(\"a2.`Artist(s)`\").alias(\"artista_2\"),\n",
    "                                 col(\"similaridade_jaccard\")\n",
    "                             ) \\\n",
    "                             .orderBy(col(\"similaridade_jaccard\").desc())\n",
    "\n",
    "    # --- 5. Salvar Resultado ---\n",
    "    print(\"Etapa 4/4: Salvando os resultados...\")\n",
    "    caminho_saida = \"/spark-data/resultados_similaridade_jaccard\"\n",
    "\n",
    "    print(f\"Workload concluído. Top 100 resultados\")\n",
    "    #df_resultado.show(20, truncate=False)\n",
    "\n",
    "\n",
    "# --- Medição do Tempo de Execução ---\n",
    "print(\"Iniciando a execução do Workload Final de Estresse...\")\n",
    "inicio = time.time()\n",
    "\n",
    "executar_workload_final()\n",
    "\n",
    "fim = time.time()\n",
    "duracao = fim - inicio\n",
    "throughput = 424/duracao\n",
    "\n",
    "print(f\"\\n--- Análise de Desempenho ---\")\n",
    "print(f\"Tempo total de execução: {duracao:.2f} segundos\")\n",
    "print(f\"Throughput da execução: {throughput:.2f} MB/s\")\n",
    "print(f\"----------------------------\")\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7539d9ff-3006-4598-b2c6-b14cbc26e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

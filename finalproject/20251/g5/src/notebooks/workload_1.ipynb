{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "905611ce-4158-40e4-b317-316556e555c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/09 04:20:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session iniciada com sucesso!\n",
      "Conectado ao Spark master: spark://spark-master:7077\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, greatest, coalesce, lit, first, when\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "import socket\n",
    "import time\n",
    "\n",
    "# --- Configuração do Spark Session ---\n",
    "local_ip = socket.gethostbyname(socket.gethostname())\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Workload 1 - Correlacao por Genero e Ano\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Session iniciada com sucesso!\")\n",
    "print(\"Conectado ao Spark master:\", spark.sparkContext.master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3224742c-234d-400b-aaa1-189a9356a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição e Execução do Workload\n",
    "\n",
    "def executar_workload1():\n",
    "    \"\"\"\n",
    "    Executa o Workload 1:\n",
    "    1. Lê o dataset limpo do Parquet.\n",
    "    2. Calcula a correlação entre a Popularidade e outras métricas numéricas,\n",
    "       agrupado por gênero e ano.\n",
    "    3. Identifica a métrica com a maior correlação para cada grupo.\n",
    "    4. Salva o resultado em um único arquivo CSV.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Carregar os Dados ---\n",
    "    caminho_parquet = \"/spark-data/musicas_limpas.parquet\"\n",
    "    df = spark.read.parquet(caminho_parquet)\n",
    "\n",
    "    # Colunas numéricas para análise de correlação\n",
    "    numeric_cols = [\n",
    "        \"Tempo\", \"Loudness (db)\", \"Energy\", \"Danceability\", \"Positiveness\",\n",
    "        \"Speechiness\", \"Liveness\", \"Acousticness\", \"Instrumentalness\"\n",
    "    ]\n",
    "\n",
    "    # --- 2. Calcular Correlações de forma Otimizada ---\n",
    "    # Cria uma expressão de correlação para cada coluna numérica com a Popularidade\n",
    "    corr_exprs = [\n",
    "        expr(f\"corr(Popularity, `{c}`)\").alias(f\"corr_{c}\") for c in numeric_cols\n",
    "    ]\n",
    "\n",
    "    # Agrupa por gênero e ano e calcula todas as correlações de uma vez\n",
    "    df_correlacoes = df.groupBy(\"main_genre\", \"release_year\").agg(*corr_exprs)\n",
    "\n",
    "    # --- 3. Encontrar a Métrica de Maior Correlação ---\n",
    "    # Nomes das novas colunas de correlação (ex: \"corr_Energy\")\n",
    "    corr_col_names = [f\"corr_{c}\" for c in numeric_cols]\n",
    "\n",
    "    # Encontra o valor máximo de correlação na linha\n",
    "    max_corr_value = greatest(*[col(c) for c in corr_col_names])\n",
    "\n",
    "    # Encontra o nome da coluna original que corresponde ao valor máximo\n",
    "    # A função coalesce retorna a primeira coluna que não é nula\n",
    "    max_corr_col_name = coalesce(*[\n",
    "        when(col(c) == max_corr_value, lit(c.replace(\"corr_\", \"\")))\n",
    "        for c in corr_col_names\n",
    "    ])\n",
    "\n",
    "    df_resultado = df_correlacoes.withColumn(\"maior_corr_coluna\", max_corr_col_name)\n",
    "\n",
    "    # --- 4. Preparar e Salvar o Resultado Final ---\n",
    "    df_final = df_resultado.select(\"main_genre\", \"release_year\", \"maior_corr_coluna\")\n",
    "    \n",
    "    print(f\"Workload 1 concluído.\")\n",
    "    df_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6367079-bf27-44a7-b3ce-fa04743a03db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a execução do Workload 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workload 1 concluído.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/09 04:20:25 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+-----------------+\n",
      "|      main_genre|release_year|maior_corr_coluna|\n",
      "+----------------+------------+-----------------+\n",
      "|            soul|        1981|     Acousticness|\n",
      "|           metal|        2008|     Danceability|\n",
      "|             emo|        2016|           Energy|\n",
      "|             rnb|        1974|           Energy|\n",
      "|           house|        2019| Instrumentalness|\n",
      "|       indie pop|        1998|     Acousticness|\n",
      "|       deathcore|        2019|           Energy|\n",
      "|           swing|        2002|            Tempo|\n",
      "|             pop|        1950|     Acousticness|\n",
      "|progressive rock|        2001|     Danceability|\n",
      "+----------------+------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "--- Análise de Desempenho ---\n",
      "Tempo total de execução: 32.72 segundos\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Medição do Tempo de Execução ---\n",
    "print(\"Iniciando a execução do Workload 1...\")\n",
    "inicio = time.time()\n",
    "\n",
    "executar_workload1()\n",
    "\n",
    "fim = time.time()\n",
    "duracao = fim - inicio\n",
    "\n",
    "print(f\"\\n--- Análise de Desempenho ---\")\n",
    "print(f\"Tempo total de execução: {duracao:.2f} segundos\")\n",
    "print(f\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7539d9ff-3006-4598-b2c6-b14cbc26e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f79c66-cd1b-45d9-b711-83ba4bae01d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/09 05:40:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session iniciada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, explode, lower, regexp_replace, collect_set, size, array_intersect\n",
    "import socket\n",
    "import time\n",
    "\n",
    "# --- Configuração do Spark Session ---\n",
    "local_ip = socket.gethostbyname(socket.gethostname())\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Workload Pesado - Vocabulario Comum Entre Generos\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Session iniciada com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf1ac47-d096-4ee8-adfa-0872f1af655b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a execução do Workload Pesado (Sem Numpy)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workload concluído.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+-----------------+\n",
      "|genero_1        |genero_2|palavras_em_comum|\n",
      "+----------------+--------+-----------------+\n",
      "|hip hop         |rock    |74271            |\n",
      "|hip hop         |rap     |53662            |\n",
      "|hip hop         |pop     |53525            |\n",
      "|pop             |rock    |42699            |\n",
      "|rap             |rock    |42571            |\n",
      "|hip hop         |jazz    |38935            |\n",
      "|electronic      |hip hop |38474            |\n",
      "|pop             |rap     |34925            |\n",
      "|alternative rock|hip hop |34198            |\n",
      "|electronic      |rock    |33560            |\n",
      "|jazz            |rock    |33406            |\n",
      "|folk            |hip hop |32331            |\n",
      "|alternative rock|rock    |31153            |\n",
      "|folk            |rock    |29437            |\n",
      "|jazz            |pop     |29297            |\n",
      "|electronic      |rap     |29284            |\n",
      "|electronic      |pop     |29216            |\n",
      "|jazz            |rap     |28869            |\n",
      "|hip hop         |pop rock|28720            |\n",
      "|country         |hip hop |27910            |\n",
      "+----------------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "--- Análise de Desempenho ---\n",
      "Tempo total de execução: 68.35 segundos\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "def executar_workload_sem_numpy():\n",
    "    \"\"\"\n",
    "    Executa um workload pesado para encontrar o número de palavras em comum\n",
    "    entre os principais gêneros musicais.\n",
    "    \"\"\"\n",
    "    # --- 1. Carregar e Preparar os Dados ---\n",
    "    caminho_parquet = \"/spark-data/musicas_limpas.parquet\"\n",
    "    df = spark.read.parquet(caminho_parquet)\n",
    "\n",
    "    # Filtra para os 10 gêneros mais populares para o teste\n",
    "    top_genres = [row['main_genre'] for row in df.groupBy(\"main_genre\").count().orderBy(col(\"count\").desc()).limit(10).collect()]\n",
    "    df_filtrado = df.filter(col(\"main_genre\").isin(top_genres))\n",
    "\n",
    "    # --- 2. Processamento e Agregação de Palavras por Gênero ---\n",
    "    df_palavras = df_filtrado.withColumn(\"palavra\", explode(split(lower(regexp_replace(col(\"text\"), r'[\\W_]+', ' ')), ' '))) \\\n",
    "                             .select(\"main_genre\", \"palavra\") \\\n",
    "                             .filter(col(\"palavra\") != \"\")\n",
    "\n",
    "    df_vocabulario_genero = df_palavras.groupBy(\"main_genre\").agg(collect_set(\"palavra\").alias(\"vocabulario\"))\n",
    "\n",
    "    # --- 3. Self-Join e Cálculo da Interseção (A PARTE PESADA) ---\n",
    "    df_g1 = df_vocabulario_genero.alias(\"g1\")\n",
    "    df_g2 = df_vocabulario_genero.alias(\"g2\")\n",
    "\n",
    "    df_pares_generos = df_g1.crossJoin(df_g2) \\\n",
    "                            .filter(col(\"g1.main_genre\") < col(\"g2.main_genre\"))\n",
    "\n",
    "    # AQUI ESTÁ A CORREÇÃO: Usamos a função correta 'array_intersect'\n",
    "    df_intersecao = df_pares_generos.withColumn(\n",
    "        \"palavras_em_comum\",\n",
    "        size(array_intersect(col(\"g1.vocabulario\"), col(\"g2.vocabulario\")))\n",
    "    )\n",
    "\n",
    "    # --- 4. Selecionar e Ordenar o Resultado Final ---\n",
    "    df_resultado = df_intersecao.select(\n",
    "        col(\"g1.main_genre\").alias(\"genero_1\"),\n",
    "        col(\"g2.main_genre\").alias(\"genero_2\"),\n",
    "        col(\"palavras_em_comum\")\n",
    "    ).orderBy(col(\"palavras_em_comum\").desc())\n",
    "\n",
    "    print(f\"Workload concluído.\")\n",
    "    df_resultado.show(20, truncate=False)\n",
    "\n",
    "\n",
    "# --- Medição do Tempo de Execução ---\n",
    "print(\"Iniciando a execução do Workload Pesado (Sem Numpy)...\")\n",
    "inicio = time.time()\n",
    "\n",
    "executar_workload_sem_numpy()\n",
    "\n",
    "fim = time.time()\n",
    "duracao = fim - inicio\n",
    "\n",
    "print(f\"\\n--- Análise de Desempenho ---\")\n",
    "print(f\"Tempo total de execução: {duracao:.2f} segundos\")\n",
    "print(f\"----------------------------\")\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f197f8e-a2d4-4bd1-8391-325563603b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d806dec8-05b3-4d13-8fe4-8cc8e917cece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

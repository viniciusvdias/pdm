{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2665f558-53d8-4586-bfa4-43830aa5384f",
   "metadata": {},
   "source": [
    "# PrÃ©-Processamento: SparkSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78793a7-6d38-4794-a7d1-6b2c0e57ca8f",
   "metadata": {},
   "source": [
    "### Step 1: Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991433e-339e-4dde-a08d-d31ce0c45a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Limpar ambiente Spark completamente\n",
    "def reset_spark():\n",
    "    for var in ['spark', 'sc', 'sqlContext']:\n",
    "        if var in globals():\n",
    "            try:\n",
    "                del globals()[var]\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Limpar mÃ³dulos\n",
    "    modules = [k for k in sys.modules.keys() if 'pyspark' in k]\n",
    "    for m in modules:\n",
    "        if m in sys.modules:\n",
    "            del sys.modules[m]\n",
    "\n",
    "reset_spark()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "try:\n",
    "    spark.stop()\n",
    "except NameError:\n",
    "    print(\"SparkContext not defined\")\n",
    "\n",
    "# local mode\n",
    "# spark = SparkSession.builder \\\n",
    "#             .appName(\"Spark SQL\") \\\n",
    "#             .master(\"local[*]\") \\\n",
    "# \t    \t.config(\"spark.jars.packages\", \"org.xerial.snappy:snappy-java:1.1.10.1\") \\\n",
    "# \t    \t.getOrCreate()\n",
    "\n",
    "# cluster mode\n",
    "spark = SparkSession.builder \\\n",
    "           .appName(\"Spark SQL basic example\") \\\n",
    "           .master(\"spark://spark-master-g7:7077\") \\\n",
    "\t    \t.config(\"spark.some.config.option\", \"some-value\") \\\n",
    "\t    \t.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ca032-e731-41e0-b385-d791eff47fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "ROOT_DIR = Path.cwd().parent\n",
    "data_path = ROOT_DIR / \"data\"\n",
    "data_raw_path = data_path / \"data_raw\"\n",
    "zip_path = data_path / \"data_raw.zip\"\n",
    "file_id = \"1wLFeP8SPEuq_Ac6cPZTFE4PlR3bYdMRP\"\n",
    "download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "\n",
    "if not data_path.exists() or not data_raw_path.exists():\n",
    "    print(f\"Pasta {data_raw_path} nÃ£o encontrada. Baixando os dados...\")\n",
    "    \n",
    "    data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    gdown.download(download_url, str(zip_path), quiet=False)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_path)\n",
    "\n",
    "    zip_path.unlink()\n",
    "\n",
    "    print(\"Download e extraÃ§Ã£o concluÃ­dos.\")\n",
    "else:\n",
    "    print(f\"Pasta {data_raw_path} encontrada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0cb7a4-6fad-4b23-a91a-fc5472b9c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "arquivos_detalhados = glob.glob(\"../data/data_raw/**/*_DETAIL_*.csv\", recursive=True)\n",
    "\n",
    "arquivos_principais = [\n",
    "    arq for arq in glob.glob(\"../data/data_raw/**/*.csv\", recursive=True)\n",
    "    if \"_DETAIL_\" not in arq\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036544d2-64ad-4c94-a4e8-c5407f4cc853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arquivos_detalhados = \"../datasample/RESTRICAO_COFF_EOLICA_DETAIL_2025_05_amostra.csv\"\n",
    "\n",
    "# arquivos_principais = \"../datasample/RESTRICAO_COFF_EOLICA_2025_05_amostra.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c59fd8-fdba-452c-b370-440bb15f88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detalhado = spark.read.option(\"delimiter\", \";\").option(\"header\", True).option(\"inferSchema\", True).csv(arquivos_detalhados)\n",
    "\n",
    "df_principal = spark.read.option(\"delimiter\", \";\").option(\"header\", True).option(\"inferSchema\", True).csv(arquivos_principais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae5c2d-482b-4d68-982a-525cd4404cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detalhado.show()\n",
    "df_detalhado.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa1473-7303-412c-8111-61636d978cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principal.show()\n",
    "df_principal.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4896424f-62cf-466c-ba76-97554d4ca211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_detalhado.write.option(\"compression\", \"uncompressed\").mode(\"overwrite\").parquet(\"../data/data_cleared/dados_detalhados.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66edea96-18c8-461a-ae01-f709c062de50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_principal.write.option(\"compression\", \"uncompressed\").mode(\"overwrite\").parquet(\"../data/data_cleared/dados_principais.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58d3240e-c46b-4c19-acc5-0ac0a496845c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando dados em CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dados salvos em CSV\n",
      "Arquivos salvos em: ../data/data_detalhado_csv/ e ../data/data_principal_csv/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(\"Salvando dados em CSV...\")\n",
    "\n",
    "# Salvar dados detalhados em CSV\n",
    "df_detalhado.coalesce(1).write.option(\"header\", \"true\").option(\"delimiter\", \";\").mode(\"overwrite\").csv(\"../data/data_detalhado_csv\")\n",
    "\n",
    "\n",
    "print(\"âœ… Dados salvos em CSV\")\n",
    "print(\"Arquivos salvos em: ../data/data_detalhado_csv/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "419f270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando transformaÃ§Ãµes aos dados...\n",
      "âœ… TransformaÃ§Ãµes aplicadas\n",
      "Colunas adicionadas: constrained_off, percentual_constrained, ano, mes, hora\n"
     ]
    }
   ],
   "source": [
    "# Aplicar transformaÃ§Ãµes aos dados principais antes de salvar\n",
    "from pyspark.sql.functions import col, when, year, month, hour\n",
    "\n",
    "print(\"Aplicando transformaÃ§Ãµes aos dados...\")\n",
    "\n",
    "# Calcular constrained-off\n",
    "df_principal = df_principal.withColumn(\n",
    "    \"constrained_off\",\n",
    "    when(col(\"val_disponibilidade\") - col(\"val_geracao\") > 0,\n",
    "         col(\"val_disponibilidade\") - col(\"val_geracao\"))\n",
    "    .otherwise(0)\n",
    ")\n",
    "\n",
    "# Calcular percentual de constrained-off\n",
    "df_principal = df_principal.withColumn(\n",
    "    \"percentual_constrained\",\n",
    "    when(col(\"val_disponibilidade\") > 0,\n",
    "         (col(\"constrained_off\") / col(\"val_disponibilidade\")) * 100)\n",
    "    .otherwise(0)\n",
    ")\n",
    "\n",
    "# Adicionar colunas temporais\n",
    "df_principal = df_principal.withColumn(\"ano\", year(\"din_instante\"))\n",
    "df_principal = df_principal.withColumn(\"mes\", month(\"din_instante\"))\n",
    "df_principal = df_principal.withColumn(\"hora\", hour(\"din_instante\"))\n",
    "\n",
    "print(\"âœ… TransformaÃ§Ãµes aplicadas\")\n",
    "print(\"Colunas adicionadas: constrained_off, percentual_constrained, ano, mes, hora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed355865-7f40-4632-91de-4551d7978259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(\"Salvando dados em CSV...\")\n",
    "# Salvar dados principais em CSV (jÃ¡ com as transformaÃ§Ãµes aplicadas)\n",
    "df_principal.coalesce(1).write.option(\"header\", \"true\").option(\"delimiter\", \";\").mode(\"overwrite\").csv(\"../data/data_principal_csv\")\n",
    "print(\"âœ… Dados salvos em CSV\")\n",
    "print(\"Arquivos salvos em: ../data/data_principal_csv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693900fe-e900-4b02-b80d-2b32c1aeaf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ“Š Para AnÃ¡lises de Performance\n",
    "**Nota**: Para anÃ¡lises comparativas de performance entre CSV e Parquet e benchmarking completo, utilize o notebook `Performance-Benchmark.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

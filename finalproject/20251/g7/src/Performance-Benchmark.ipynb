{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a4e90c",
   "metadata": {},
   "source": [
    "# üìä Performance Benchmark: CSV vs Parquet\n",
    "## Sistema Completo de Benchmark Comparativo\n",
    "\n",
    "Este notebook realiza an√°lises de performance comparando o desempenho de workloads Spark usando dados em formato CSV versus Parquet, utilizando as queries reais do projeto.\n",
    "\n",
    "### Objetivos:\n",
    "- Comparar tempo de execu√ß√£o entre CSV e Parquet\n",
    "- Analisar uso de mem√≥ria e throughput\n",
    "- Executar queries de detec√ß√£o de anomalias em ambos os formatos\n",
    "- Gerar relat√≥rios de performance detalhados com recomenda√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa069e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import psutil\n",
    "import gc\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Limpar ambiente Spark completamente\n",
    "def reset_spark():\n",
    "    for var in ['spark', 'sc', 'sqlContext']:\n",
    "        if var in globals():\n",
    "            try:\n",
    "                del globals()[var]\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Limpar m√≥dulos\n",
    "    modules = [k for k in sys.modules.keys() if 'pyspark' in k]\n",
    "    for m in modules:\n",
    "        if m in sys.modules:\n",
    "            del sys.modules[m]\n",
    "\n",
    "reset_spark()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, year, month, hour, to_timestamp\n",
    "\n",
    "# Configurar estilo dos gr√°ficos\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üì¶ Bibliotecas carregadas com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f185fc9",
   "metadata": {},
   "source": [
    "## Classe de Benchmark para Compara√ß√£o de Formatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatBenchmark:\n",
    "    \"\"\"Classe para benchmark comparativo entre CSV e Parquet com diferentes configura√ß√µes de workers/paralelismo\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "        self.baseline_memory = psutil.virtual_memory().used / (1024**3)\n",
    "        self.spark_configs = self._define_spark_configurations()\n",
    "    \n",
    "    def _define_spark_configurations(self):\n",
    "        \"\"\"Definir diferentes configura√ß√µes de Spark para teste\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                'name': '1_WORKER',\n",
    "                'workers': 1,\n",
    "                'parallelism': 2,\n",
    "                'partitions': 2,\n",
    "                'master': 'local[1]'\n",
    "            },\n",
    "            {\n",
    "                'name': '2_WORKERS', \n",
    "                'workers': 2,\n",
    "                'parallelism': 4,\n",
    "                'partitions': 4,\n",
    "                'master': 'local[2]'\n",
    "            },\n",
    "            {\n",
    "                'name': '4_WORKERS',\n",
    "                'workers': 4, \n",
    "                'parallelism': 8,\n",
    "                'partitions': 8,\n",
    "                'master': 'local[4]'\n",
    "            },\n",
    "            {\n",
    "                'name': 'ALL_CORES',\n",
    "                'workers': None,  # Usa todos os cores\n",
    "                'parallelism': 16,\n",
    "                'partitions': 16,\n",
    "                'master': 'local[*]'\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def create_spark_session(self, format_type, config):\n",
    "        \"\"\"Criar sess√£o Spark com configura√ß√£o espec√≠fica\"\"\"\n",
    "        try:\n",
    "            spark.stop()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        app_name = f\"Benchmark_{format_type}_{config['name']}\"\n",
    "        builder = SparkSession.builder.appName(app_name).master(config['master'])\n",
    "        \n",
    "        # Configura√ß√µes comuns\n",
    "        builder = builder \\\n",
    "            .config(\"spark.default.parallelism\", config['parallelism']) \\\n",
    "            .config(\"spark.sql.shuffle.partitions\", config['partitions']) \\\n",
    "            .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "            .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "            .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "        \n",
    "        # Configura√ß√µes espec√≠ficas por formato\n",
    "        if format_type == \"PARQUET\":\n",
    "            builder = builder \\\n",
    "                .config(\"spark.sql.parquet.columnarReaderBatchSize\", \"4096\") \\\n",
    "                .config(\"spark.sql.parquet.compression.codec\", \"snappy\") \\\n",
    "                .config(\"spark.sql.parquet.enableVectorizedReader\", \"true\")\n",
    "        else:\n",
    "            builder = builder \\\n",
    "                .config(\"spark.sql.csv.parser.columnPruning.enabled\", \"true\")\n",
    "        \n",
    "        return builder.getOrCreate()\n",
    "    \n",
    "    def benchmark_workload(self, workload_func, workload_name, format_type, iterations=3):\n",
    "        \"\"\"Executar benchmark de um workload\"\"\"\n",
    "        for i in range(iterations):\n",
    "            gc.collect()\n",
    "            \n",
    "            spark = self.create_spark_session(format_type)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            start_memory = psutil.virtual_memory().used / (1024**3)\n",
    "            \n",
    "            try:\n",
    "                records = workload_func(spark)\n",
    "                \n",
    "                end_time = time.time()\n",
    "                end_memory = psutil.virtual_memory().used / (1024**3)\n",
    "                \n",
    "                result = {\n",
    "                    'workload': workload_name,\n",
    "                    'format': format_type,\n",
    "                    'iteration': i + 1,\n",
    "                    'execution_time': end_time - start_time,\n",
    "                    'memory_used': end_memory - start_memory,\n",
    "                    'records_processed': records,\n",
    "                    'throughput': records / (end_time - start_time) if (end_time - start_time) > 0 else 0,\n",
    "                    'timestamp': datetime.now()\n",
    "                }\n",
    "                \n",
    "                self.results.append(result)\n",
    "                print(f\"  {format_type} iter {i+1}: {result['execution_time']:.2f}s, {records} registros, {result['throughput']:.2f} rec/s\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Erro {format_type} iter {i+1}: {e}\")\n",
    "            finally:\n",
    "                try:\n",
    "                    spark.stop()\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    def get_comparison_summary(self):\n",
    "        \"\"\"Gerar resumo comparativo\"\"\"\n",
    "        df = pd.DataFrame(self.results)\n",
    "        if df.empty:\n",
    "            return df\n",
    "        \n",
    "        summary = df.groupby(['workload', 'format']).agg({\n",
    "            'execution_time': 'mean',\n",
    "            'memory_used': 'mean',\n",
    "            'throughput': 'mean',\n",
    "            'records_processed': 'first'\n",
    "        }).round(3)\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def get_speedup_analysis(self):\n",
    "        \"\"\"Calcular speedup do Parquet em rela√ß√£o ao CSV\"\"\"\n",
    "        df = pd.DataFrame(self.results)\n",
    "        if df.empty:\n",
    "            return df\n",
    "        \n",
    "        # Pivot para ter CSV e Parquet lado a lado\n",
    "        pivot = df.groupby(['workload', 'format'])['execution_time'].mean().unstack('format')\n",
    "        \n",
    "        if 'CSV' in pivot.columns and 'PARQUET' in pivot.columns:\n",
    "            speedup_df = pd.DataFrame({\n",
    "                'CSV_time_s': pivot['CSV'],\n",
    "                'Parquet_time_s': pivot['PARQUET'],\n",
    "                'speedup_factor': (pivot['CSV'] / pivot['PARQUET']).round(2),\n",
    "                'time_saved_s': (pivot['CSV'] - pivot['PARQUET']).round(2),\n",
    "                'improvement_pct': ((pivot['CSV'] - pivot['PARQUET']) / pivot['CSV'] * 100).round(1)\n",
    "            })\n",
    "            return speedup_df\n",
    "        \n",
    "        return pd.DataFrame()\n",
    "\n",
    "benchmark = FormatBenchmark()\n",
    "print(\"‚úÖ Classe de benchmark criada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c6c22",
   "metadata": {},
   "source": [
    "## Defini√ß√£o das Queries de Anomalia do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries de detec√ß√£o de anomalias do projeto\n",
    "queries = {\n",
    "    \"anomalia_constrained_off_extremo\": \"\"\"\n",
    "    -- Detectar usinas com constrained-off extremamente alto\n",
    "    SELECT \n",
    "        nom_usina,\n",
    "        nom_estado,\n",
    "        ano,\n",
    "        mes,\n",
    "        AVG(percentual_constrained) as percentual_medio,\n",
    "        MAX(percentual_constrained) as percentual_max,\n",
    "        COUNT(*) as registros\n",
    "    FROM wind_data\n",
    "    WHERE percentual_constrained > 50  -- Mais de 50% de constrained-off\n",
    "    GROUP BY nom_usina, nom_estado, ano, mes\n",
    "    HAVING AVG(percentual_constrained) > 70  -- M√©dia acima de 70%\n",
    "    ORDER BY percentual_medio DESC\n",
    "    \"\"\",\n",
    "    \n",
    "    \"anomalia_padrao_temporal\": \"\"\"\n",
    "    -- Detectar padr√µes temporais an√¥malos\n",
    "    SELECT \n",
    "        nom_usina,\n",
    "        nom_estado,\n",
    "        hora,\n",
    "        AVG(percentual_constrained) as percentual_medio_hora,\n",
    "        COUNT(*) as registros_hora\n",
    "    FROM wind_data\n",
    "    GROUP BY nom_usina, nom_estado, hora\n",
    "    HAVING AVG(percentual_constrained) > 30\n",
    "    ORDER BY percentual_medio_hora DESC\n",
    "    \"\"\",\n",
    "    \n",
    "    \"anomalia_cluster_espacial\": \"\"\"\n",
    "    -- Detectar clusters espaciais de anomalias\n",
    "    WITH state_anomalies AS (\n",
    "        SELECT \n",
    "            nom_estado,\n",
    "            ano,\n",
    "            mes,\n",
    "            AVG(percentual_constrained) as percentual_estado,\n",
    "            COUNT(DISTINCT nom_usina) as num_usinas_afetadas\n",
    "        FROM wind_data\n",
    "        WHERE percentual_constrained > 30\n",
    "        GROUP BY nom_estado, ano, mes\n",
    "    )\n",
    "    SELECT \n",
    "        nom_estado,\n",
    "        ano,\n",
    "        mes,\n",
    "        percentual_estado,\n",
    "        num_usinas_afetadas,\n",
    "        CASE \n",
    "            WHEN percentual_estado > 50 AND num_usinas_afetadas > 3 THEN 'CLUSTER_CRITICO'\n",
    "            WHEN percentual_estado > 30 AND num_usinas_afetadas > 2 THEN 'CLUSTER_MODERADO'\n",
    "            ELSE 'ISOLADO'\n",
    "        END as tipo_cluster\n",
    "    FROM state_anomalies\n",
    "    WHERE percentual_estado > 30\n",
    "    ORDER BY percentual_estado DESC, num_usinas_afetadas DESC\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "print(\"üîç Queries de anomalia definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec7722b",
   "metadata": {},
   "source": [
    "## Workloads de Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_csv_loading(spark):\n",
    "    \"\"\"Carregamento e transforma√ß√µes b√°sicas - CSV\"\"\"\n",
    "    df = spark.read.option(\"delimiter\", \";\").option(\"header\", True).option(\"inferSchema\", True) \\\n",
    "        .csv(\"../datasample/RESTRICAO_COFF_EOLICA_2025_05_amostra.csv\")\n",
    "    \n",
    "    # Aplicar transforma√ß√µes\n",
    "    df = df.withColumn(\"constrained_off\", \n",
    "                      when(col(\"val_disponibilidade\") - col(\"val_geracao\") > 0,\n",
    "                           col(\"val_disponibilidade\") - col(\"val_geracao\")).otherwise(0))\n",
    "    \n",
    "    df = df.withColumn(\"percentual_constrained\",\n",
    "                      when(col(\"val_disponibilidade\") > 0,\n",
    "                           (col(\"constrained_off\") / col(\"val_disponibilidade\")) * 100).otherwise(0))\n",
    "    \n",
    "    df = df.withColumn(\"ano\", year(\"din_instante\")) \\\n",
    "           .withColumn(\"mes\", month(\"din_instante\")) \\\n",
    "           .withColumn(\"hora\", hour(\"din_instante\"))\n",
    "    \n",
    "    return df.count()\n",
    "\n",
    "def workload_parquet_loading(spark):\n",
    "    \"\"\"Carregamento e transforma√ß√µes b√°sicas - Parquet\"\"\"\n",
    "    df = spark.read.parquet(\"../data/data_cleared/dados_principais.parquet\")\n",
    "    \n",
    "    # Verificar se transforma√ß√µes j√° existem\n",
    "    if \"constrained_off\" not in df.columns:\n",
    "        df = df.withColumn(\"constrained_off\", \n",
    "                          when(col(\"val_disponibilidade\") - col(\"val_geracao\") > 0,\n",
    "                               col(\"val_disponibilidade\") - col(\"val_geracao\")).otherwise(0))\n",
    "    \n",
    "    if \"percentual_constrained\" not in df.columns:\n",
    "        df = df.withColumn(\"percentual_constrained\",\n",
    "                          when(col(\"val_disponibilidade\") > 0,\n",
    "                               (col(\"constrained_off\") / col(\"val_disponibilidade\")) * 100).otherwise(0))\n",
    "    \n",
    "    if \"ano\" not in df.columns:\n",
    "        df = df.withColumn(\"ano\", year(\"din_instante\")) \\\n",
    "               .withColumn(\"mes\", month(\"din_instante\")) \\\n",
    "               .withColumn(\"hora\", hour(\"din_instante\"))\n",
    "    \n",
    "    return df.count()\n",
    "\n",
    "def workload_csv_queries(spark):\n",
    "    \"\"\"Queries de anomalia em CSV\"\"\"\n",
    "    df = spark.read.option(\"delimiter\", \";\").option(\"header\", True).option(\"inferSchema\", True) \\\n",
    "        .csv(\"../datasample/RESTRICAO_COFF_EOLICA_2025_05_amostra.csv\")\n",
    "    \n",
    "    # Preparar dados\n",
    "    df = df.withColumn(\"constrained_off\", \n",
    "                      when(col(\"val_disponibilidade\") - col(\"val_geracao\") > 0,\n",
    "                           col(\"val_disponibilidade\") - col(\"val_geracao\")).otherwise(0))\n",
    "    df = df.withColumn(\"percentual_constrained\",\n",
    "                      when(col(\"val_disponibilidade\") > 0,\n",
    "                           (col(\"constrained_off\") / col(\"val_disponibilidade\")) * 100).otherwise(0))\n",
    "    df = df.withColumn(\"ano\", year(\"din_instante\")) \\\n",
    "           .withColumn(\"mes\", month(\"din_instante\")) \\\n",
    "           .withColumn(\"hora\", hour(\"din_instante\"))\n",
    "    \n",
    "    df.createOrReplaceTempView(\"wind_data\")\n",
    "    \n",
    "    # Executar todas as queries\n",
    "    total_results = 0\n",
    "    for query_name, sql_query in queries.items():\n",
    "        result = spark.sql(sql_query)\n",
    "        total_results += result.count()\n",
    "    \n",
    "    return total_results\n",
    "\n",
    "def workload_parquet_queries(spark):\n",
    "    \"\"\"Queries de anomalia em Parquet\"\"\"\n",
    "    df = spark.read.parquet(\"../data/data_cleared/dados_principais.parquet\")\n",
    "    \n",
    "    # Verificar transforma√ß√µes\n",
    "    if \"percentual_constrained\" not in df.columns:\n",
    "        df = df.withColumn(\"constrained_off\", \n",
    "                          when(col(\"val_disponibilidade\") - col(\"val_geracao\") > 0,\n",
    "                               col(\"val_disponibilidade\") - col(\"val_geracao\")).otherwise(0))\n",
    "        df = df.withColumn(\"percentual_constrained\",\n",
    "                          when(col(\"val_disponibilidade\") > 0,\n",
    "                               (col(\"constrained_off\") / col(\"val_disponibilidade\")) * 100).otherwise(0))\n",
    "    \n",
    "    if \"ano\" not in df.columns:\n",
    "        df = df.withColumn(\"ano\", year(\"din_instante\")) \\\n",
    "               .withColumn(\"mes\", month(\"din_instante\")) \\\n",
    "               .withColumn(\"hora\", hour(\"din_instante\"))\n",
    "    \n",
    "    df.createOrReplaceTempView(\"wind_data\")\n",
    "    \n",
    "    # Executar todas as queries\n",
    "    total_results = 0\n",
    "    for query_name, sql_query in queries.items():\n",
    "        result = spark.sql(sql_query)\n",
    "        total_results += result.count()\n",
    "    \n",
    "    return total_results\n",
    "\n",
    "print(\"üöÄ Workloads definidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e283f598",
   "metadata": {},
   "source": [
    "## Execu√ß√£o dos Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14d7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar benchmarks com todas as configura√ß√µes\n",
    "print(\"üöÄ Iniciando benchmark completo com m√∫ltiplas configura√ß√µes...\")\n",
    "\n",
    "# Usar as fun√ß√µes corretas definidas anteriormente\n",
    "workloads = [\n",
    "    (\"CARREGAMENTO_DADOS\", workload_csv_loading, workload_parquet_loading),\n",
    "    (\"QUERIES_ANOMALIA\", workload_csv_queries, workload_parquet_queries),\n",
    "]\n",
    "\n",
    "# Benchmark para cada configura√ß√£o de Spark\n",
    "for config in benchmark.spark_configs:\n",
    "    config_name = f\"w{config['workers']}_p{config['parallelism']}\"\n",
    "    print(f\"\\nüìä Testando configura√ß√£o: {config_name} (Workers={config['workers']}, Parallelism={config['parallelism']}, Memory={config['memory']})\")\n",
    "    \n",
    "    for workload_name, csv_func, parquet_func in workloads:\n",
    "        print(f\"  üîç Testando {workload_name}\")\n",
    "        \n",
    "        # Teste CSV\n",
    "        print(f\"    üìÑ CSV:\")\n",
    "        benchmark.benchmark_workload(csv_func, workload_name, \"CSV\", config, iterations=2)\n",
    "        \n",
    "        # Teste Parquet  \n",
    "        print(f\"    üìä PARQUET:\")\n",
    "        benchmark.benchmark_workload(parquet_func, workload_name, \"PARQUET\", config, iterations=2)\n",
    "\n",
    "print(\"\\n‚úÖ Benchmark completo finalizado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b1bc5",
   "metadata": {},
   "source": [
    "## An√°lise dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f33bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise comparativa\n",
    "print(\"=== AN√ÅLISE COMPARATIVA ===\\n\")\n",
    "\n",
    "summary = benchmark.get_comparison_summary()\n",
    "if not summary.empty:\n",
    "    print(\"üìä Resumo por Workload e Formato:\")\n",
    "    print(summary.to_string())\n",
    "    \n",
    "    # Calcular speedup\n",
    "    speedup_data = benchmark.get_speedup_analysis()\n",
    "    if not speedup_data.empty:\n",
    "        print(f\"\\nüöÄ SPEEDUP (Parquet vs CSV):\")\n",
    "        print(speedup_data.to_string())\n",
    "        \n",
    "        print(f\"\\nüí° INSIGHTS DE PERFORMANCE:\")\n",
    "        for workload, row in speedup_data.iterrows():\n",
    "            if row['speedup_factor'] > 1.2:\n",
    "                print(f\"  ‚úÖ {workload}: Parquet √© {row['speedup_factor']:.1f}x mais r√°pido ({row['improvement_pct']:.1f}% de melhoria)\")\n",
    "            elif row['speedup_factor'] > 0.8:\n",
    "                print(f\"  ‚ûñ {workload}: Performance similar entre formatos\")\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è  {workload}: CSV pode ser mais r√°pido\")\n",
    "        \n",
    "        print(f\"\\nüéØ RECOMENDA√á√ïES:\")\n",
    "        avg_speedup = speedup_data['speedup_factor'].mean()\n",
    "        if avg_speedup > 1.2:\n",
    "            print(f\"  üìä Use Parquet para este tipo de workload (speedup m√©dio: {avg_speedup:.1f}x)\")\n",
    "        elif avg_speedup > 0.8:\n",
    "            print(f\"  ‚öñÔ∏è  Ambos os formatos t√™m performance similar\")\n",
    "        else:\n",
    "            print(f\"  üìÑ CSV pode ser mais adequado para este caso\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# An√°lise detalhada dos resultados\n",
    "print(\"üìä AN√ÅLISE DETALHADA DOS RESULTADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not benchmark.results:\n",
    "    print(\"‚ö†Ô∏è Nenhum resultado dispon√≠vel para an√°lise\")\n",
    "else:\n",
    "    # 1. Tabela comparativa principal CSV vs Parquet\n",
    "    print(\"\\n1Ô∏è‚É£ COMPARA√á√ÉO CSV vs PARQUET POR CONFIGURA√á√ÉO\")\n",
    "    comparison_table = benchmark.get_format_comparison_table()\n",
    "    if not comparison_table.empty:\n",
    "        print(comparison_table.to_string(index=False))\n",
    "        print(f\"\\nüîç Insights da compara√ß√£o:\")\n",
    "        avg_time_improvement = comparison_table['time_improvement_pct'].mean()\n",
    "        avg_throughput_improvement = comparison_table['throughput_improvement_pct'].mean()\n",
    "        print(f\"   ‚Ä¢ Parquet √© {avg_time_improvement:.1f}% mais r√°pido em m√©dia\")\n",
    "        print(f\"   ‚Ä¢ Parquet tem {avg_throughput_improvement:.1f}% mais throughput em m√©dia\")\n",
    "        \n",
    "        best_config = comparison_table.loc[comparison_table['throughput_speedup'].idxmax()]\n",
    "        print(f\"   ‚Ä¢ Melhor configura√ß√£o: {best_config['config']} ({best_config['throughput_speedup']:.2f}x speedup)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Nenhum resultado encontrado para compara√ß√£o\")\n",
    "\n",
    "    # 2. An√°lise de escalabilidade\n",
    "    print(\"\\n\\n2Ô∏è‚É£ AN√ÅLISE DE ESCALABILIDADE\")\n",
    "    scalability = benchmark.get_scalability_analysis()\n",
    "    if not scalability.empty:\n",
    "        print(\"\\nEfici√™ncia paralela por formato:\")\n",
    "        for fmt in scalability['format'].unique():\n",
    "            fmt_data = scalability[scalability['format'] == fmt]\n",
    "            print(f\"\\n{fmt}:\")\n",
    "            for _, row in fmt_data.iterrows():\n",
    "                print(f\"  {row['parallelism']} cores: {row['parallel_efficiency']:.1f}% efici√™ncia, {row['speedup']:.2f}x speedup\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Dados insuficientes para an√°lise de escalabilidade\")\n",
    "\n",
    "    # 3. Resumo detalhado por configura√ß√£o\n",
    "    print(\"\\n\\n3Ô∏è‚É£ RESUMO DETALHADO POR CONFIGURA√á√ÉO\")\n",
    "    detailed_summary = benchmark.get_detailed_comparison()\n",
    "    if not detailed_summary.empty:\n",
    "        print(detailed_summary.to_string())\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Nenhum resultado detalhado dispon√≠vel\")\n",
    "\n",
    "    # 4. M√©tricas de efici√™ncia de recursos\n",
    "    print(\"\\n\\n4Ô∏è‚É£ EFICI√äNCIA DE RECURSOS\")\n",
    "    df = pd.DataFrame(benchmark.results)\n",
    "    \n",
    "    # Verificar se as colunas existem antes de usar\n",
    "    available_columns = df.columns.tolist()\n",
    "    print(f\"Colunas dispon√≠veis: {available_columns}\")\n",
    "    \n",
    "    if 'config_name' in df.columns and 'efficiency' in df.columns:\n",
    "        resource_efficiency = df.groupby(['format', 'config_name']).agg({\n",
    "            'efficiency': 'mean',\n",
    "            'memory_used': 'mean'\n",
    "        }).round(3)\n",
    "        print(resource_efficiency.to_string())\n",
    "        \n",
    "        # Identificar configura√ß√£o mais eficiente\n",
    "        best_efficiency = df.loc[df['efficiency'].idxmax()]\n",
    "        print(f\"\\nüèÜ Configura√ß√£o mais eficiente:\")\n",
    "        print(f\"   ‚Ä¢ Formato: {best_efficiency['format']}\")\n",
    "        print(f\"   ‚Ä¢ Configura√ß√£o: {best_efficiency['config_name']}\")\n",
    "        print(f\"   ‚Ä¢ Efici√™ncia: {best_efficiency['efficiency']:.0f} registros/segundo/core\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Colunas necess√°rias n√£o encontradas para an√°lise de efici√™ncia\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed48361",
   "metadata": {},
   "source": [
    "## Visualiza√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a23036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°ficos comparativos\n",
    "if benchmark.results:\n",
    "    df_results = pd.DataFrame(benchmark.results)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Benchmark: CSV vs Parquet', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Tempo de execu√ß√£o\n",
    "    pivot_time = df_results.groupby(['workload', 'format'])['execution_time'].mean().unstack('format')\n",
    "    if not pivot_time.empty:\n",
    "        pivot_time.plot(kind='bar', ax=axes[0,0], title='Tempo de Execu√ß√£o')\n",
    "        axes[0,0].set_ylabel('Tempo (segundos)')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Throughput\n",
    "    pivot_throughput = df_results.groupby(['workload', 'format'])['throughput'].mean().unstack('format')\n",
    "    if not pivot_throughput.empty:\n",
    "        pivot_throughput.plot(kind='bar', ax=axes[0,1], title='Throughput')\n",
    "        axes[0,1].set_ylabel('Registros/segundo')\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Uso de mem√≥ria\n",
    "    pivot_memory = df_results.groupby(['workload', 'format'])['memory_used'].mean().unstack('format')\n",
    "    if not pivot_memory.empty:\n",
    "        pivot_memory.plot(kind='bar', ax=axes[1,0], title='Uso de Mem√≥ria')\n",
    "        axes[1,0].set_ylabel('Mem√≥ria (GB)')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Speedup\n",
    "    speedup_data = benchmark.get_speedup_analysis()\n",
    "    if not speedup_data.empty and 'speedup_factor' in speedup_data.columns:\n",
    "        speedup_data['speedup_factor'].plot(kind='bar', ax=axes[1,1], title='Speedup Factor')\n",
    "        axes[1,1].set_ylabel('Speedup (Parquet vs CSV)')\n",
    "        axes[1,1].axhline(y=1, color='red', linestyle='--', alpha=0.7)\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Nenhum resultado para visualizar\")\n",
    "\n",
    "# Visualiza√ß√µes avan√ßadas\n",
    "print(\"üìà GERANDO VISUALIZA√á√ïES...\")\n",
    "\n",
    "if not benchmark.results:\n",
    "    print(\"‚ö†Ô∏è Nenhum resultado dispon√≠vel para visualiza√ß√£o\")\n",
    "else:\n",
    "    df = pd.DataFrame(benchmark.results)\n",
    "    print(f\"üìä Dataset com {len(df)} registros e colunas: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Configurar matplotlib\n",
    "    plt.style.use('default')\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Gr√°fico de barras - Tempo de execu√ß√£o por configura√ß√£o\n",
    "    plt.subplot(3, 3, 1)\n",
    "    comparison_data = benchmark.get_format_comparison_table()\n",
    "    if not comparison_data.empty:\n",
    "        x = range(len(comparison_data))\n",
    "        width = 0.35\n",
    "        plt.bar([i - width/2 for i in x], comparison_data['csv_time_s'], width, label='CSV', alpha=0.7, color='red')\n",
    "        plt.bar([i + width/2 for i in x], comparison_data['parquet_time_s'], width, label='Parquet', alpha=0.7, color='green')\n",
    "        plt.xlabel('Configura√ß√£o')\n",
    "        plt.ylabel('Tempo (segundos)')\n",
    "        plt.title('Tempo de Execu√ß√£o por Configura√ß√£o')\n",
    "        plt.xticks(x, comparison_data['config'], rotation=45)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Dados insuficientes\\npara compara√ß√£o', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Tempo de Execu√ß√£o por Configura√ß√£o')\n",
    "    \n",
    "    # 2. Gr√°fico de throughput\n",
    "    plt.subplot(3, 3, 2)\n",
    "    if not comparison_data.empty:\n",
    "        plt.bar([i - width/2 for i in x], comparison_data['csv_throughput'], width, label='CSV', alpha=0.7, color='red')\n",
    "        plt.bar([i + width/2 for i in x], comparison_data['parquet_throughput'], width, label='Parquet', alpha=0.7, color='green')\n",
    "        plt.xlabel('Configura√ß√£o')\n",
    "        plt.ylabel('Throughput (registros/s)')\n",
    "        plt.title('Throughput por Configura√ß√£o')\n",
    "        plt.xticks(x, comparison_data['config'], rotation=45)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Dados insuficientes\\npara throughput', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Throughput por Configura√ß√£o')\n",
    "    \n",
    "    # 3. Speedup por paralelismo\n",
    "    plt.subplot(3, 3, 3)\n",
    "    scalability = benchmark.get_scalability_analysis()\n",
    "    if not scalability.empty:\n",
    "        for fmt in scalability['format'].unique():\n",
    "            fmt_data = scalability[scalability['format'] == fmt]\n",
    "            plt.plot(fmt_data['parallelism'], fmt_data['speedup'], 'o-', label=fmt, linewidth=2, markersize=8)\n",
    "        plt.plot([1, scalability['parallelism'].max()], [1, scalability['parallelism'].max()], '--', \n",
    "                 color='gray', alpha=0.5, label='Speedup Linear Ideal')\n",
    "        plt.xlabel('Paralelismo (cores)')\n",
    "        plt.ylabel('Speedup')\n",
    "        plt.title('Escalabilidade - Speedup vs Paralelismo')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Dados insuficientes\\npara escalabilidade', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Escalabilidade - Speedup vs Paralelismo')\n",
    "    \n",
    "    # 4. Efici√™ncia paralela\n",
    "    plt.subplot(3, 3, 4)\n",
    "    if not scalability.empty and 'parallel_efficiency' in scalability.columns:\n",
    "        for fmt in scalability['format'].unique():\n",
    "            fmt_data = scalability[scalability['format'] == fmt]\n",
    "            plt.plot(fmt_data['parallelism'], fmt_data['parallel_efficiency'], 's-', label=fmt, linewidth=2, markersize=8)\n",
    "        plt.axhline(y=100, color='gray', linestyle='--', alpha=0.5, label='Efici√™ncia Ideal (100%)')\n",
    "        plt.xlabel('Paralelismo (cores)')\n",
    "        plt.ylabel('Efici√™ncia Paralela (%)')\n",
    "        plt.title('Efici√™ncia Paralela por Paralelismo')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Dados insuficientes\\npara efici√™ncia', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Efici√™ncia Paralela por Paralelismo')\n",
    "    \n",
    "    # 5. Tempo de execu√ß√£o simples por formato\n",
    "    plt.subplot(3, 3, 5)\n",
    "    if 'format' in df.columns and 'execution_time' in df.columns:\n",
    "        format_times = df.groupby('format')['execution_time'].mean()\n",
    "        format_times.plot(kind='bar', ax=plt.gca(), color=['red', 'green'], alpha=0.7)\n",
    "        plt.title('Tempo M√©dio de Execu√ß√£o por Formato')\n",
    "        plt.ylabel('Tempo (segundos)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Dados insuficientes\\npara tempo por formato', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Tempo M√©dio de Execu√ß√£o por Formato')\n",
    "    \n",
    "    # 6. Uso de mem√≥ria por configura√ß√£o\n",
    "    plt.subplot(3, 3, 6)\n",
    "    if 'config_name' in df.columns and 'memory_used' in df.columns:\n",
    "        memory_data = df.groupby(['format', 'config_name'])['memory_used'].mean().reset_index()\n",
    "        csv_memory = memory_data[memory_data['format'] == 'CSV']\n",
    "        parquet_memory = memory_data[memory_data['format'] == 'PARQUET']\n",
    "        \n",
    "        if not csv_memory.empty and not parquet_memory.empty:\n",
    "            x_pos = range(len(csv_memory))\n",
    "            width = 0.35\n",
    "            plt.bar([i - width/2 for i in x_pos], csv_memory['memory_used'], width, label='CSV', alpha=0.7, color='red')\n",
    "            plt.bar([i + width/2 for i in x_pos], parquet_memory['memory_used'], width, label='Parquet', alpha=0.7, color='green')\n",
    "            plt.xlabel('Configura√ß√£o')\n",
    "            plt.ylabel('Uso de Mem√≥ria (GB)')\n",
    "            plt.title('Uso de Mem√≥ria por Configura√ß√£o')\n",
    "            plt.xticks(x_pos, csv_memory['config_name'], rotation=45)\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, 'Dados insuficientes\\npara mem√≥ria', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "            plt.title('Uso de Mem√≥ria por Configura√ß√£o')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Dados insuficientes\\npara mem√≥ria', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Uso de Mem√≥ria por Configura√ß√£o')\n",
    "    \n",
    "    # 7. Throughput por formato\n",
    "    plt.subplot(3, 3, 7)\n",
    "    if 'throughput' in df.columns:\n",
    "        throughput_data = df.groupby('format')['throughput'].mean()\n",
    "        throughput_data.plot(kind='bar', ax=plt.gca(), color=['red', 'green'], alpha=0.7)\n",
    "        plt.title('Throughput M√©dio por Formato')\n",
    "        plt.ylabel('Registros/segundo')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Dados insuficientes\\npara throughput', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Throughput M√©dio por Formato')\n",
    "    \n",
    "    # 8. Speedup de throughput CSV vs Parquet\n",
    "    plt.subplot(3, 3, 8)\n",
    "    if not comparison_data.empty and 'throughput_speedup' in comparison_data.columns:\n",
    "        colors = ['green' if x > 1 else 'red' for x in comparison_data['throughput_speedup']]\n",
    "        plt.bar(range(len(comparison_data)), comparison_data['throughput_speedup'], \n",
    "                color=colors, alpha=0.7)\n",
    "        plt.axhline(y=1, color='black', linestyle='-', alpha=0.5, label='Sem speedup')\n",
    "        plt.xlabel('Configura√ß√£o')\n",
    "        plt.ylabel('Speedup de Throughput (Parquet/CSV)')\n",
    "        plt.title('Speedup de Throughput: Parquet vs CSV')\n",
    "        plt.xticks(range(len(comparison_data)), comparison_data['config'], rotation=45)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Dados insuficientes\\npara speedup', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Speedup de Throughput: Parquet vs CSV')\n",
    "    \n",
    "    # 9. Resumo geral dos resultados\n",
    "    plt.subplot(3, 3, 9)\n",
    "    summary_text = f\"\"\"\n",
    "RESUMO BENCHMARK\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "Total de testes: {len(df)}\n",
    "Formatos: {', '.join(df['format'].unique())}\n",
    "Workloads: {', '.join(df['workload'].unique())}\n",
    "\n",
    "Tempo m√©dio CSV: {df[df['format']=='CSV']['execution_time'].mean():.2f}s\n",
    "Tempo m√©dio Parquet: {df[df['format']=='PARQUET']['execution_time'].mean():.2f}s\n",
    "\"\"\"\n",
    "    plt.text(0.1, 0.5, summary_text, fontsize=10, ha='left', va='center', \n",
    "             transform=plt.gca().transAxes, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.title('Resumo dos Resultados')\n",
    "    \n",
    "    plt.tight_layout(pad=3.0)\n",
    "    \n",
    "    # Salvar gr√°fico\n",
    "    os.makedirs('/home/fellipe-brandao/pdm/finalproject/20251/g7/results', exist_ok=True)\n",
    "    plt.savefig('/home/fellipe-brandao/pdm/finalproject/20251/g7/results/performance_analysis_advanced.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Visualiza√ß√µes salvas em results/performance_analysis_advanced.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a61d2",
   "metadata": {},
   "source": [
    "## Relat√≥rio Final e Exporta√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f881bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relat√≥rio final\n",
    "print(\"=\"*80)\n",
    "print(\"RELAT√ìRIO FINAL DE BENCHMARK: CSV vs PARQUET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if benchmark.results:\n",
    "    total_tests = len(benchmark.results)\n",
    "    workloads_tested = len(set([r['workload'] for r in benchmark.results]))\n",
    "    \n",
    "    print(f\"\\nüìä RESUMO GERAL:\")\n",
    "    print(f\"   ‚Ä¢ Total de testes realizados: {total_tests}\")\n",
    "    print(f\"   ‚Ä¢ Workloads testados: {workloads_tested}\")\n",
    "    print(f\"   ‚Ä¢ Formatos comparados: CSV e Parquet\")\n",
    "    \n",
    "    # An√°lise de speedup\n",
    "    speedup_data = benchmark.get_speedup_analysis()\n",
    "    if not speedup_data.empty:\n",
    "        avg_speedup = speedup_data['speedup_factor'].mean()\n",
    "        best_speedup = speedup_data['speedup_factor'].max()\n",
    "        \n",
    "        print(f\"\\nüöÄ PERFORMANCE GERAL:\")\n",
    "        print(f\"   ‚Ä¢ Speedup m√©dio do Parquet: {avg_speedup:.2f}x\")\n",
    "        print(f\"   ‚Ä¢ Melhor speedup: {best_speedup:.2f}x\")\n",
    "        \n",
    "        if avg_speedup > 1.2:\n",
    "            print(f\"   ‚úÖ Parquet demonstra performance superior significativa\")\n",
    "        elif avg_speedup > 0.8:\n",
    "            print(f\"   ‚ûñ Performance similar entre formatos\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  CSV demonstra performance superior em alguns casos\")\n",
    "    \n",
    "    print(f\"\\nüìã DIRETRIZES GERAIS:\")\n",
    "    print(f\"   ‚Ä¢ Para workloads de leitura intensiva: Prefira Parquet\")\n",
    "    print(f\"   ‚Ä¢ Para an√°lises complexas: Parquet oferece melhor performance\")\n",
    "    print(f\"   ‚Ä¢ Para dados que mudam frequentemente: Considere CSV para simplicidade\")\n",
    "    print(f\"   ‚Ä¢ Para armazenamento: Parquet oferece melhor compress√£o\")\n",
    "\n",
    "# Salvar resultados\n",
    "results_dir = Path(\"../results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Salvar em JSON\n",
    "with open(results_dir / f\"benchmark_results_{timestamp}.json\", 'w') as f:\n",
    "    json.dump(benchmark.results, f, indent=2, default=str)\n",
    "\n",
    "# Salvar resumo em CSV\n",
    "summary = benchmark.get_comparison_summary()\n",
    "if not summary.empty:\n",
    "    summary.to_csv(results_dir / f\"benchmark_summary_{timestamp}.csv\")\n",
    "\n",
    "# Salvar speedup\n",
    "speedup_data = benchmark.get_speedup_analysis()\n",
    "if not speedup_data.empty:\n",
    "    speedup_data.to_csv(results_dir / f\"speedup_analysis_{timestamp}.csv\")\n",
    "\n",
    "print(f\"\\nüìÅ ARQUIVOS GERADOS:\")\n",
    "print(f\"   ‚Ä¢ Resultados completos: benchmark_results_{timestamp}.json\")\n",
    "print(f\"   ‚Ä¢ Resumo: benchmark_summary_{timestamp}.csv\")\n",
    "if not speedup_data.empty:\n",
    "    print(f\"   ‚Ä¢ An√°lise de speedup: speedup_analysis_{timestamp}.csv\")\n",
    "\n",
    "print(f\"\\nüìÇ Todos os arquivos salvos em: {results_dir.absolute()}\")\n",
    "print(\"\\n‚úÖ BENCHMARK FINALIZADO COM SUCESSO!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Exportar resultados e relat√≥rio final\n",
    "print(\"üíæ EXPORTANDO RESULTADOS...\")\n",
    "\n",
    "# Criar diret√≥rio se n√£o existir\n",
    "os.makedirs('/home/fellipe-brandao/pdm/finalproject/20251/g7/results', exist_ok=True)\n",
    "\n",
    "if not benchmark.results:\n",
    "    print(\"‚ö†Ô∏è Nenhum resultado para exportar\")\n",
    "else:\n",
    "    # 1. Resultados brutos em JSON e CSV\n",
    "    results_df = pd.DataFrame(benchmark.results)\n",
    "    \n",
    "    # Exportar JSON com todos os detalhes\n",
    "    with open('/home/fellipe-brandao/pdm/finalproject/20251/g7/results/benchmark_results_detailed.json', 'w') as f:\n",
    "        json.dump(benchmark.results, f, indent=2, default=str)\n",
    "    \n",
    "    # Exportar CSV para an√°lise externa\n",
    "    results_df.to_csv('/home/fellipe-brandao/pdm/finalproject/20251/g7/results/benchmark_results_detailed.csv', \n",
    "                      index=False)\n",
    "    \n",
    "    # 2. Tabela comparativa principal\n",
    "    comparison_table = benchmark.get_format_comparison_table()\n",
    "    if not comparison_table.empty:\n",
    "        comparison_table.to_csv('/home/fellipe-brandao/pdm/finalproject/20251/g7/results/format_comparison.csv', \n",
    "                               index=False)\n",
    "        print(\"‚úÖ Tabela comparativa salva em format_comparison.csv\")\n",
    "    \n",
    "    # 3. An√°lise de escalabilidade\n",
    "    scalability = benchmark.get_scalability_analysis()\n",
    "    if not scalability.empty:\n",
    "        scalability.to_csv('/home/fellipe-brandao/pdm/finalproject/20251/g7/results/scalability_analysis.csv', \n",
    "                          index=False)\n",
    "        print(\"‚úÖ An√°lise de escalabilidade salva em scalability_analysis.csv\")\n",
    "    \n",
    "    # 4. Estat√≠sticas b√°sicas\n",
    "    total_tests = len(benchmark.results)\n",
    "    csv_data = results_df[results_df['format'] == 'CSV']\n",
    "    parquet_data = results_df[results_df['format'] == 'PARQUET']\n",
    "    \n",
    "    if not csv_data.empty and not parquet_data.empty:\n",
    "        avg_csv_time = csv_data['execution_time'].mean()\n",
    "        avg_parquet_time = parquet_data['execution_time'].mean()\n",
    "        overall_speedup = avg_csv_time / avg_parquet_time if avg_parquet_time > 0 else 0\n",
    "        \n",
    "        # 5. Resumo executivo\n",
    "        summary_report = [\n",
    "            {'metric': 'Total de testes executados', 'value': str(total_tests), 'unit': 'testes'},\n",
    "            {'metric': 'Tempo m√©dio CSV', 'value': f\"{avg_csv_time:.2f}\", 'unit': 'segundos'},\n",
    "            {'metric': 'Tempo m√©dio Parquet', 'value': f\"{avg_parquet_time:.2f}\", 'unit': 'segundos'},\n",
    "            {'metric': 'Speedup geral (Parquet vs CSV)', 'value': f\"{overall_speedup:.2f}\", 'unit': 'x mais r√°pido'}\n",
    "        ]\n",
    "        \n",
    "        # Melhor configura√ß√£o (se dispon√≠vel)\n",
    "        if not comparison_table.empty:\n",
    "            best_config = comparison_table.loc[comparison_table['throughput_speedup'].idxmax()]\n",
    "            summary_report.append({\n",
    "                'metric': 'Melhor configura√ß√£o',\n",
    "                'value': f\"{best_config['config']} ({best_config['throughput_speedup']:.2f}x speedup)\",\n",
    "                'unit': 'configura√ß√£o'\n",
    "            })\n",
    "        \n",
    "        # Salvar resumo executivo\n",
    "        summary_df = pd.DataFrame(summary_report)\n",
    "        summary_df.to_csv('/home/fellipe-brandao/pdm/finalproject/20251/g7/results/executive_summary.csv', \n",
    "                          index=False)\n",
    "        \n",
    "        # 6. Relat√≥rio final em texto\n",
    "        with open('/home/fellipe-brandao/pdm/finalproject/20251/g7/results/benchmark_report.txt', 'w') as f:\n",
    "            f.write(\"RELAT√ìRIO DE BENCHMARK - SPARK CSV vs PARQUET\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            f.write(f\"Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Total de testes: {total_tests}\\n\\n\")\n",
    "            \n",
    "            f.write(\"RESUMO EXECUTIVO:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            for item in summary_report:\n",
    "                f.write(f\"{item['metric']}: {item['value']} {item['unit']}\\n\")\n",
    "            \n",
    "            f.write(f\"\\nRESULTADOS DETALHADOS:\\n\")\n",
    "            f.write(\"-\" * 25 + \"\\n\")\n",
    "            if not comparison_table.empty:\n",
    "                f.write(comparison_table.to_string(index=False))\n",
    "            else:\n",
    "                f.write(\"Dados insuficientes para tabela comparativa detalhada\\n\")\n",
    "            \n",
    "            f.write(f\"\\n\\nAN√ÅLISE DE ESCALABILIDADE:\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "            if not scalability.empty:\n",
    "                f.write(scalability.to_string(index=False))\n",
    "            else:\n",
    "                f.write(\"Dados insuficientes para an√°lise de escalabilidade\\n\")\n",
    "            \n",
    "            f.write(f\"\\n\\nRECOMENDA√á√ïES:\\n\")\n",
    "            f.write(\"-\" * 15 + \"\\n\")\n",
    "            if overall_speedup > 1.5:\n",
    "                f.write(\"‚Ä¢ Use formato Parquet para melhor performance\\n\")\n",
    "            elif overall_speedup > 1.0:\n",
    "                f.write(\"‚Ä¢ Parquet oferece melhor performance, mas ganho √© moderado\\n\")\n",
    "            else:\n",
    "                f.write(\"‚Ä¢ CSV e Parquet t√™m performance similar neste workload\\n\")\n",
    "                \n",
    "            if not comparison_table.empty:\n",
    "                best_config = comparison_table.loc[comparison_table['throughput_speedup'].idxmax()]\n",
    "                f.write(f\"‚Ä¢ Configura√ß√£o recomendada: {best_config['config']}\\n\")\n",
    "                f.write(f\"‚Ä¢ Speedup esperado: {best_config['throughput_speedup']:.2f}x\\n\")\n",
    "        \n",
    "        print(\"‚úÖ Resultados exportados:\")\n",
    "        print(\"   ‚Ä¢ benchmark_results_detailed.json/csv - Dados brutos\")\n",
    "        print(\"   ‚Ä¢ format_comparison.csv - Compara√ß√£o CSV vs Parquet\")\n",
    "        print(\"   ‚Ä¢ scalability_analysis.csv - An√°lise de escalabilidade\")\n",
    "        print(\"   ‚Ä¢ executive_summary.csv - Resumo executivo\")\n",
    "        print(\"   ‚Ä¢ benchmark_report.txt - Relat√≥rio completo\")\n",
    "        \n",
    "        # Relat√≥rio final na tela\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RELAT√ìRIO FINAL DE BENCHMARK: CSV vs PARQUET\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nüìä RESUMO GERAL:\")\n",
    "        print(f\"   ‚Ä¢ Total de testes realizados: {total_tests}\")\n",
    "        print(f\"   ‚Ä¢ Formatos comparados: CSV e Parquet\")\n",
    "        print(f\"   ‚Ä¢ Workloads testados: {len(results_df['workload'].unique())}\")\n",
    "        \n",
    "        print(f\"\\nüöÄ PERFORMANCE GERAL:\")\n",
    "        print(f\"   ‚Ä¢ Tempo m√©dio CSV: {avg_csv_time:.2f}s\")\n",
    "        print(f\"   ‚Ä¢ Tempo m√©dio Parquet: {avg_parquet_time:.2f}s\")\n",
    "        print(f\"   ‚Ä¢ Speedup m√©dio do Parquet: {overall_speedup:.2f}x\")\n",
    "        \n",
    "        if overall_speedup > 1.5:\n",
    "            print(f\"   ‚úÖ Parquet demonstra performance superior significativa\")\n",
    "        elif overall_speedup > 1.0:\n",
    "            print(f\"   ‚ûñ Parquet tem performance ligeiramente melhor\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  Performance similar entre formatos\")\n",
    "        \n",
    "        print(f\"\\nüìã DIRETRIZES GERAIS:\")\n",
    "        print(f\"   ‚Ä¢ Para workloads de leitura intensiva: Prefira Parquet\")\n",
    "        print(f\"   ‚Ä¢ Para an√°lises complexas: Parquet oferece melhor performance\")\n",
    "        print(f\"   ‚Ä¢ Para dados que mudam frequentemente: Considere CSV para simplicidade\")\n",
    "        print(f\"   ‚Ä¢ Para armazenamento: Parquet oferece melhor compress√£o\")\n",
    "\n",
    "print(\"\\nüéâ BENCHMARK COMPLETO FINALIZADO!\")\n",
    "print(\"üìÅ Todos os arquivos salvos em: finalproject/20251/g7/results/\")\n",
    "print(\"\\nüìä Para visualizar os resultados:\")\n",
    "print(\"   1. Abra os arquivos CSV no Excel/LibreOffice\")\n",
    "print(\"   2. Visualize o relat√≥rio em benchmark_report.txt\")\n",
    "print(\"   3. Analise os gr√°ficos em performance_analysis_advanced.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
